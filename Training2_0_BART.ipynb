{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6855b9307374106aa1cdee3dbcba5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9230d7451a564b538f2b25c23d4b3a87",
              "IPY_MODEL_52f82f4520e54cbd86ad4eac7ea2a3ed",
              "IPY_MODEL_5b8799b91dfe45e3a638dffe6bc49b38"
            ],
            "layout": "IPY_MODEL_d639208e7ae24eb2a34da443696f1faa"
          }
        },
        "9230d7451a564b538f2b25c23d4b3a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b750c54ab46d4815bee32b72b694e8d1",
            "placeholder": "​",
            "style": "IPY_MODEL_20e4b0a1c6104b46bee48165f75aba4d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "52f82f4520e54cbd86ad4eac7ea2a3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a68e279e2cb41dbb47cbeff1f37bcbc",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c81f4bceec8b49d0812b0fa12395df7d",
            "value": 26
          }
        },
        "5b8799b91dfe45e3a638dffe6bc49b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a088d7ad75d940a38830286f843ff75c",
            "placeholder": "​",
            "style": "IPY_MODEL_f5b8f26ad9314fbb840d2474e29e3d65",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.29kB/s]"
          }
        },
        "d639208e7ae24eb2a34da443696f1faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b750c54ab46d4815bee32b72b694e8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e4b0a1c6104b46bee48165f75aba4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a68e279e2cb41dbb47cbeff1f37bcbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81f4bceec8b49d0812b0fa12395df7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a088d7ad75d940a38830286f843ff75c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b8f26ad9314fbb840d2474e29e3d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6afcf446887040ad90a20db2349ea13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee2adb6dfc0343dd82d815e5d2a4a639",
              "IPY_MODEL_f09f2c3d23664e7098431f8489426a74",
              "IPY_MODEL_94601652a52648418aeca63d993b2a96"
            ],
            "layout": "IPY_MODEL_c95324ea395545ef894c93dd3459f9f1"
          }
        },
        "ee2adb6dfc0343dd82d815e5d2a4a639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf1adffdea04cb386ea757c334c92e2",
            "placeholder": "​",
            "style": "IPY_MODEL_4dd674902d094a62af47ec950f027975",
            "value": "vocab.json: 100%"
          }
        },
        "f09f2c3d23664e7098431f8489426a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2218308a8a4342abac404607cf7386de",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d36b4709007e4b2f8a8ebdf3a7b5add7",
            "value": 898822
          }
        },
        "94601652a52648418aeca63d993b2a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04be2457b3f444a91bc2ded330801bd",
            "placeholder": "​",
            "style": "IPY_MODEL_f268d27cf6c54d869857760d34a2e3d6",
            "value": " 899k/899k [00:00&lt;00:00, 4.01MB/s]"
          }
        },
        "c95324ea395545ef894c93dd3459f9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf1adffdea04cb386ea757c334c92e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd674902d094a62af47ec950f027975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2218308a8a4342abac404607cf7386de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36b4709007e4b2f8a8ebdf3a7b5add7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a04be2457b3f444a91bc2ded330801bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f268d27cf6c54d869857760d34a2e3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c44478b52ec747d2b61edce5cdb0ecc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6976dd260c424c72bb7078af615919e6",
              "IPY_MODEL_efb4c8ca2dc2464f9d0068943c685e79",
              "IPY_MODEL_0ffbd2426a4a4c92891bda91c4c15438"
            ],
            "layout": "IPY_MODEL_512c6cfebe1e47cbb36f0f0c90f4442a"
          }
        },
        "6976dd260c424c72bb7078af615919e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7038a08a694f648d98bd5fe35e37b8",
            "placeholder": "​",
            "style": "IPY_MODEL_9f516be3f8a2422dadbc483cd7d29ef0",
            "value": "merges.txt: 100%"
          }
        },
        "efb4c8ca2dc2464f9d0068943c685e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c132c3d45c4947a8031cc1dba3f5e2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f26305a7d9e94d44894085a4b0308999",
            "value": 456318
          }
        },
        "0ffbd2426a4a4c92891bda91c4c15438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00852f6b2be4e8d8750d6b6a277808b",
            "placeholder": "​",
            "style": "IPY_MODEL_fc2eb2281740409c9dfca838b52d47e3",
            "value": " 456k/456k [00:00&lt;00:00, 4.03MB/s]"
          }
        },
        "512c6cfebe1e47cbb36f0f0c90f4442a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7038a08a694f648d98bd5fe35e37b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f516be3f8a2422dadbc483cd7d29ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4c132c3d45c4947a8031cc1dba3f5e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26305a7d9e94d44894085a4b0308999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b00852f6b2be4e8d8750d6b6a277808b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2eb2281740409c9dfca838b52d47e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "221c9a99974945a1a7b4ee6cbf130d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4e3d31125ee41a5bf5692ab0dfacdcc",
              "IPY_MODEL_b818829cdffd46b4888eee3cd7e39486",
              "IPY_MODEL_965047dd2558465baf1680a867f3c687"
            ],
            "layout": "IPY_MODEL_27e8655572654d8496ea28a4f3d68aa3"
          }
        },
        "f4e3d31125ee41a5bf5692ab0dfacdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c95410823b4e809456a856de5d25a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a0d035c351bf4479bc5828fae8116fdc",
            "value": "tokenizer.json: 100%"
          }
        },
        "b818829cdffd46b4888eee3cd7e39486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343ba9cf5814441e8712fdf12b80233c",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e56ab636bec64851a554e02c33d3be89",
            "value": 1355863
          }
        },
        "965047dd2558465baf1680a867f3c687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a2a7879a18945fa98466b7105219fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_fa4c7c31e6484bc3a9c4b221f015aef0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.94MB/s]"
          }
        },
        "27e8655572654d8496ea28a4f3d68aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c95410823b4e809456a856de5d25a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d035c351bf4479bc5828fae8116fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "343ba9cf5814441e8712fdf12b80233c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56ab636bec64851a554e02c33d3be89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a2a7879a18945fa98466b7105219fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4c7c31e6484bc3a9c4b221f015aef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88950abbd9074b98b9d7ae034855100d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12e98b7a1e784d919263e0deeed69ab2",
              "IPY_MODEL_0138c0dbb4234d2ca3f3c66b7583836b",
              "IPY_MODEL_59a0f97a7d2f4fe699494d7b21203802"
            ],
            "layout": "IPY_MODEL_758ce034838b4878a9f817958c913373"
          }
        },
        "12e98b7a1e784d919263e0deeed69ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcf5b9d3b8a74ccb8aef76c7347dff2d",
            "placeholder": "​",
            "style": "IPY_MODEL_dd8ab05b58f64e3da98660f34a4bd701",
            "value": "config.json: 100%"
          }
        },
        "0138c0dbb4234d2ca3f3c66b7583836b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5955b1587634b1b820a828add51ff9e",
            "max": 1628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21753c10fc114a5082507bd2e6f87e62",
            "value": 1628
          }
        },
        "59a0f97a7d2f4fe699494d7b21203802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55552f3446f4e279a5d0f282ae30f82",
            "placeholder": "​",
            "style": "IPY_MODEL_6002c79e13994c93b7f5231784ce8612",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 135kB/s]"
          }
        },
        "758ce034838b4878a9f817958c913373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf5b9d3b8a74ccb8aef76c7347dff2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8ab05b58f64e3da98660f34a4bd701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5955b1587634b1b820a828add51ff9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21753c10fc114a5082507bd2e6f87e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c55552f3446f4e279a5d0f282ae30f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6002c79e13994c93b7f5231784ce8612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58937aec44f84ff2bef21dd1790d36ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f00b0c7d8c954284ae9d1e8a541bf163",
              "IPY_MODEL_ecfbaa33bb834460b34e9b6874c3e996",
              "IPY_MODEL_a325dd071cd9448380ea2467cf591f6b"
            ],
            "layout": "IPY_MODEL_3070f1b3a43e4454beddf94ee7f2aa76"
          }
        },
        "f00b0c7d8c954284ae9d1e8a541bf163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b606aea467452cbe4f91305dc036b9",
            "placeholder": "​",
            "style": "IPY_MODEL_46a490fe18ee4803a4ba0d3afb4f69a2",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "ecfbaa33bb834460b34e9b6874c3e996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d11a056412445d92e67162c2839075",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96d8428a37874f52befded9b6838d3df",
            "value": 1000
          }
        },
        "a325dd071cd9448380ea2467cf591f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f22020325f4999b62c65ac545302d1",
            "placeholder": "​",
            "style": "IPY_MODEL_8a46ddf3a92f4a88a87bbe23de6e7736",
            "value": " 1000/1000 [00:05&lt;00:00, 133.37 examples/s]"
          }
        },
        "3070f1b3a43e4454beddf94ee7f2aa76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b606aea467452cbe4f91305dc036b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a490fe18ee4803a4ba0d3afb4f69a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d11a056412445d92e67162c2839075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d8428a37874f52befded9b6838d3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0f22020325f4999b62c65ac545302d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a46ddf3a92f4a88a87bbe23de6e7736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65abdb07e8af46918521a134ae8a9d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d758e4a2c70a49adae8bc25ae6d0d2bd",
              "IPY_MODEL_c0497028630b4866aff2ca9d0606ac10",
              "IPY_MODEL_5afe6fba1d52413988fdcc387a40aae8"
            ],
            "layout": "IPY_MODEL_0ec14907b25d4e3a99a8c544f05bebc0"
          }
        },
        "d758e4a2c70a49adae8bc25ae6d0d2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1137b60631b44c3286bb2835f4479d04",
            "placeholder": "​",
            "style": "IPY_MODEL_44e188ba62464fe9b5375cc6cd7c5da4",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c0497028630b4866aff2ca9d0606ac10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccaec4919257482f86c258c3986b78ee",
            "max": 1018571383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dda53dc9f204288a71ad81ac2438395",
            "value": 1018571383
          }
        },
        "5afe6fba1d52413988fdcc387a40aae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b02139ff1144cda4f1ea8e09ac8b5b",
            "placeholder": "​",
            "style": "IPY_MODEL_b00850bd2cc34b4295ebb824e050d7fc",
            "value": " 1.02G/1.02G [00:04&lt;00:00, 227MB/s]"
          }
        },
        "0ec14907b25d4e3a99a8c544f05bebc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1137b60631b44c3286bb2835f4479d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e188ba62464fe9b5375cc6cd7c5da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccaec4919257482f86c258c3986b78ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dda53dc9f204288a71ad81ac2438395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57b02139ff1144cda4f1ea8e09ac8b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00850bd2cc34b4295ebb824e050d7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "KFWuWxG_dQOB",
        "outputId": "d6911643-1715-4caa-968f-7dae0b8025f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Installing collected packages: xxhash, Mako, dill, colorlog, multiprocess, alembic, optuna, datasets\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 optuna-3.6.1 xxhash-3.4.1\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.0\n",
            "    Uninstalling transformers-4.41.0:\n",
            "      Successfully uninstalled transformers-4.41.0\n",
            "Successfully installed transformers-4.41.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'accelerate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8e3f22819d47>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install accelerate -U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers -U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accelerate version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transformers version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accelerate' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets optuna tensorboard\n",
        "!pip install accelerate -U\n",
        "!pip install transformers -U\n",
        "print(\"Accelerate version:\", accelerate.__version__)\n",
        "print(\"Transformers version:\", transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess"
      ],
      "metadata": {
        "id": "E5DZdBgxku9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "sum_df = pd.read_csv('/content/drive/MyDrive/TrainingBart/summary_dataset.csv')\n",
        "sum_df.head()\n",
        "ori_df = pd.read_csv('/content/drive/MyDrive/TrainingBart/earning_calls_transcript_1k.csv')\n",
        "ori_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w6kojJQYkqD1",
        "outputId": "65bd7269-a200-45f7-ad5d-c0ecb6863fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Exchange Symbol  Year                              EarningCallTranscript\n",
              "0      NMS   MSFT  2021  Operator: Greetings, and welcome to the Micros...\n",
              "1      NMS   MSFT  2021  Operator: Greetings, and welcome to the Micros...\n",
              "2      NMS   MSFT  2021  Operator: Greetings, and welcome to the Micros...\n",
              "3      NMS   MSFT  2021  Operator: Greetings, and welcome to the Micros...\n",
              "4      NMS   MSFT  2022  Operator: Greetings, and welcome to the Micros..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2221d61-b851-4550-9cdc-3b05b300cb77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exchange</th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Year</th>\n",
              "      <th>EarningCallTranscript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NMS</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2021</td>\n",
              "      <td>Operator: Greetings, and welcome to the Micros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NMS</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2021</td>\n",
              "      <td>Operator: Greetings, and welcome to the Micros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NMS</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2021</td>\n",
              "      <td>Operator: Greetings, and welcome to the Micros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NMS</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2021</td>\n",
              "      <td>Operator: Greetings, and welcome to the Micros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NMS</td>\n",
              "      <td>MSFT</td>\n",
              "      <td>2022</td>\n",
              "      <td>Operator: Greetings, and welcome to the Micros...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2221d61-b851-4550-9cdc-3b05b300cb77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2221d61-b851-4550-9cdc-3b05b300cb77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2221d61-b851-4550-9cdc-3b05b300cb77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0eb20fa7-6b41-4f67-ae1b-d3d470353598\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0eb20fa7-6b41-4f67-ae1b-d3d470353598')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0eb20fa7-6b41-4f67-ae1b-d3d470353598 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ori_df",
              "summary": "{\n  \"name\": \"ori_df\",\n  \"rows\": 1794,\n  \"fields\": [\n    {\n      \"column\": \"Exchange\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NYQ\",\n          \"NMS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 151,\n        \"samples\": [\n          \"MU\",\n          \"JNJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2021,\n        \"max\": 2023,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2021,\n          2022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EarningCallTranscript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1793,\n        \"samples\": [\n          \"Operator: Ladies and gentlemen, thank you for standing by, and welcome to the Synopsys Earnings Conference Call for the First Quarter of Fiscal Year 2021. At this time, all participants are in a listen-only mode. Later, we will conduct a question-and-answer session and instructions will be given at that time. [Operator Instructions] Today's call will last one hour. Five minutes prior to the end of the call, we will announce the amount of time remaining in the conference. As a reminder, today's call is being recorded. And at this time, I would like to turn the conference over to Lisa Ewbank, Vice President of Investor Relations. Please go ahead.\\nLisa Ewbank: Thank you, Laurie. Good afternoon, everyone. With us today are Art de Geus, Chairman and Co-CEO of Synopsys; and Trac Pham, Chief Financial Officer. Before we begin, I'd like to remind everyone that during the course of this conference call, Synopsys will discuss forecasts, targets and other forward-looking statements regarding the Company and its financial results. While these statements represent our best current judgment about future results and performance as of today, our actual results are subject to many risks and uncertainties that could cause actual results to differ materially from what we expect. In addition to any risks that we highlight during the call, important factors that may affect our future results are described in our most recent SEC reports and today's earnings press release. In addition, we will refer to non-GAAP financial measures during the discussion. Reconciliations to their most directly comparable GAAP financial measures and supplemental financial information can be found in the earnings press release, financial supplement and 8-K that we released earlier today. All of these items, plus the most recent Investor Presentation are available on our website at synopsys.com. In addition, the prepared remarks will be posted on the site at the conclusion of the call. Finally, we are again all participating from different locations today. Please forgive any delays, technology glitches or awkward handoffs in the Q&A session that occur as a result. Thank you very much for that. And with that, I'll turn the call over to Aart de Geus.\\nAart de Geus: Good afternoon. Q1 was a very good start to the year as we met or exceeded all of our guidance targets. Revenue was $970 million, with GAAP earnings per share of $1.03 and non-GAAP earnings above our target range at $1.52. The business was strong across all geographies and product groups. And for the year, we are reaffirming our guidance with low to mid-teens non-GAAP EPS growth, revenues surpassing the $4 billion milestone, non-GAAP operating margin of 29% to 30% and more than $1 billion in operating cash flow. Meanwhile, our markets are strong. Wherever one looks, be it at AI and machine learning, hyperscale-enabled cloud computing, 5G, next-generation automotive, massively connected IoT or software enhanced medical devices all require more chips and software. Chips to store and move huge amounts of IoT data through the cloud, chips for massive general compute and AI-driven smarts in every vertical end market, still more chips to tie these huge hardware-software systems seamlessly together and make them both secure and save and the escalating need for ever more secure software with embedded on an electronic system or in the enterprise software space. This is the center of gravity for Synopsys With our product portfolio that not only excel in advanced system-on-chip design, but reaches down into the critical foundation of silicon manufacturing and up to the intensifying needs of smart software, we are uniquely positioned at the heart of this opportunity space. It's quite rewarding to see the adoption and business momentum of the innovations we've introduced over the past several years and the enthusiasm around our further expansions into brand-new domains through our next wave of technology disruptions. Let me share some highlights, beginning with EDA. Our groundbreaking Fusion Design Platform continues to drive proliferation and competitive displacements, supporting strong revenue growth. This includes major expansions and evaluations at historical competitor strongholds. Customers clearly recognize our leadership at the most advanced nodes now down to 5- and 3-nanometer. Our Fusion Compiler product, specifically deliver superior performance, power and area results with numerous competitive wins and wide deployments with influential, high-impact semi and systems companies around the world, we see growing business momentum. Integral to our sustainable differentiation is native integration of our golden signoff product, which guarantees the most accurate and timely results. Our deep collaboration with foundries ensures that our mutual customers can access the most advanced technologies with well honed design flows. This quarter, for example, we announced the collaboration with Samsung Foundry to deliver the fastest design closure and signoff for five and three nanometers. We continue to also see good growth and momentum in custom. We again added several new Custom Compiler customers, including two in the wireless communications segment, also further inroads with memory companies who are adopting our complete end-to-end custom solution. A never-ending challenge in today's complex designs is verification not only of the chips, but also the intersection of the chips with the software that runs on top of them. Our verification continuing platform is uniquely powerful in this sweet spot of modern design and is driving strong growth. Adoptions are expanding rapidly at influential customers, ranging from leading hyperscalers to automotive to the most sophisticated global semis and systems companies. For example, AWS which utilizes our verification software to accelerate the development of data center chips and automotive supplier automotive for its autonomous driving applications. Strong demand continues for our market-leading hardware solutions. Just this quarter, we added 10 new customers and had 45 repeat orders. The power of our comprehensive design plus verification solution is evident in full portfolio adoption. This quarter, it included a global design services leader who adopted both Fusion and Verification platforms for highly complex designs, replacing their legacy tools. Now to IP, where we again delivered strong double-digit revenue growth. Outsourcing of sophisticated IP blocks continues unabated. Our track record of innovation, reliability and advanced node leadership have led to our number one position in interface, embedded memory and foundry-specific IP. We provide the broadest portfolio by far, accelerating time-to-market and reducing risk for our customers. This quarter, we continued to show strong momentum across multiple applications and products. In high-performance compute, which is one of the most dynamic segments today, our comprehensive IP portfolio has driven more than 450 wins in 7-nanometer and over 100 in 5-nanometer. We achieved silicon proof of our 112-gigabit Ethernet PHY on 5-nanometer, driving the leading-edge in this key product area. With the tremendous growth in Internet traffic, security is a big concern in protecting the data transfer in hyperscale cloud centers. This quarter, we launched the industry's first security IP modules for PCI Express 5.0 and CXL communication interfaces. We have already secured the first design win with a growing pipeline. Building on our lead and advanced technology, we released the first phases of our 3-nanometer foundation IP offerings. Building on our innovation and momentum in EDA and IP, we have invested in unique and breakthrough solutions to next-generation challenges that our customers face. We do this in close collaboration with ecosystem partners through a combination of R&D and technology acquisitions. While we have a number of these in our innovation pipeline, let me highlight three that we recently announced: one, 3D multi-die design; two, AI-driven design flows; and three, silicon life cycle management. Starting with 3D multi-die design. Think of it as combining and stacking multiple die together not on the board, but on a specialized large chip. This leads to extremely tight configuration with much higher data speed and bandwidth than with a traditional board and packages approach. Our new 3DIC Compiler product enables the design and analysis of these complex 3D systems, taking full advantage of our technical breadth by leveraging both Fusion Compiler and our signoff tools. Early momentum is building rapidly with expanding evaluations and adoptions. Designers are seeing the performance and capacity benefits of a single environment and are beginning to move away from older mix-and-match solutions. For example, 3DIC Compiler helped a large Asian semiconductor company complete a highly advanced test chip in record time, saving weeks of design time. With this, we also combined our high-bandwidth memory and die-to-die IP that enables interconnecting these complex systems. Moving next to AI-driven design. We have a breakthrough and already award-winning new solution, DSO.ai. DSO stands for Design Space Optimization. While maximizing the contribution of engineering teams, DSO.ai leverages machine learning techniques and computation to explore the design space for still better solutions in terms of chip performance, power and area. This autonomous search substantially accelerates the work of the human design team. Indeed, in Q1, customers using DSO.ai reported remarkable productivity improvements, consistently realizing better results in a fraction of the time and effort typically required. On top of that, multiple production tape-outs have recently been completed. Our customers are already holding DSO.ai as an anchor product and are beginning to deploy across their organizations. Finally, Silicon Lifecycle Management, a new platform to monitor, analyze and optimize chips as they are designed, manufactured, tested and deployed in the field. Synopsys is uniquely well equipped to provide a comprehensive solution through our long-standing expertise in design, manufacturing and IP. We add sensors, monitors and data analytics on chip to provide insight to test yield and reliability management tools. This gives smart visibility into critical performance, reliability, safety and security issues for chip's entire lifespan. In Q1, we expanded our capabilities with the acquisition of Moortec which provides leading-edge process, voltage and temperature sensors. Initial interest and activity are strong and expanding. We're in talks with a number of leading IDM and fabless customers. We're also engaged with major cloud service providers to deploy aspects of our solution into their platforms. These new innovation areas create not only new business growth opportunities they also leverage strong cross disciplinary expertise in Synopsys from design to manufacturing to IP. Now to Software Integrity, testing software code for security vulnerabilities and quality issues. We delivered a solid beginning to the year and are on track towards meeting our fiscal '21 goals to reaccelerate growth. As I mentioned in December, we have implemented several important enhancements, all showing encouraging progress. First, evolving our go-to-market strategy and customer success organization including tuning our sales coverage and building an indirect channel program; second, bolstering our strategic consulting capabilities to better serve growing market needs; and third, evolving our product road map to capitalize on the latest security trend. These improvements are beginning to show in our results. All geographies delivered at or above plan. We have numerous multimillion-dollar new agreements and sizable expansions with customers ranging from industrials and aerospace to electronics and financial services. The trend towards adoption of multiple products continues. Customer interest in a consulting-led approach to software security is growing. Recent publicized security breaches only underscore that need. Our expanded team is ramping up, and we see very good long-term opportunity. In addition, industry analysts continue to recognize the quality and breadth of our portfolio. Synopsys was again named a leader in the Forrester Wave for static application security testing. To summarize, Q1 was a very good start to the year. We delivered strong financial results and are reaffirming our outlook for fiscal Our markets are healthy as customer investment in critical chip and system designs as well as immense amounts of software remains very strong. Our differentiated portfolio of solutions including exciting innovations in brand-new areas of technology disruption is generating high demand and strong growth. Lastly, keep an eye out for our second annual corporate social responsibility report to be published in the next few weeks. We're proud of the progress we've made in the areas of environmental stewardship, social solidarity and corporate governance. We look forward to sharing with you our metrics and future objectives. With that, I'll turn it over to Trac.\\nTrac Pham: Thanks, Aart. Good afternoon, everyone. We delivered a very strong start to the year and continue to execute well on our short- and long-term targets. We grew revenue broadly across all product groups and geographies. We reported non-GAAP earnings above our target range and continue to expand non-GAAP operating margin. We produced another quarter of robust collections, leading to a very strong cash flow, and we announced a $250 million repurchase in the quarter. Our strong start, market leadership and the resiliency of our business model with nearly 90% recurring revenue gives us the confidence to reiterate our 2021 financial targets. I'll now review our first quarter results. All comparisons are year-over-year unless otherwise stated. We grew total revenue to $970 million, up 16% as design activity generally and demand for our products in particular remained high. The quarter also reflected the timing of some product shipments shifting forward into Q1. Semiconductor and System Design segment revenue was $878 million, with and System Design segment revenue was $878 million, with both EDA and IP performing well. Software Integrity segment revenue was $92 million, a solid start towards our full year objectives. Moving on to expenses. Total GAAP costs and expenses were $822 million. Total non-GAAP costs and expenses were $684 million, resulting in a non-GAAP operating margin of 29.6%. Adjusted operating margin for Semiconductor & System Design was 31.8% as Software Integrity was 8.6%. Finally, GAAP earnings per share were $1.03, and non-GAAP earnings per share were $1.52. Turning to cash. We generated $174 million in operating cash flow, our highest first quarter operating cash flow to date driven by strong collections and a couple of large customer payments that came in early. We initiated a $250 million stock repurchase, consistent with our commitment to increasing buybacks this year. We ended the quarter with a cash balance of $1.02 billion and total debt of $123 million. I'll now provide our guidance. We are reiterating a very solid outlook growth and profitability for the year. Revenue of $4 billion to $4.05 billion; total GAAP costs and expenses between $3.234 billion and $3.279 billion; total non-GAAP cost and expenses between $2.825 billion and $2.855 billion, a non-GAAP operating margin of 29% to 30%; Other income and expenses between minus $11 million and minus $7 million; of 60%; GAAP earnings of $4.29 to $4.45 per share; non-GAAP earnings of $6.23 to $6.3 per share; cash flow from operations of $1.2 to $1.3 billion, and capital expenditures of approximately $100 million. Now to the targets for the second quarter. Revenue between $970 million and $1 billion, total GAAP costs and expenses between $801 million and $819 million, total non-GAAP costs and expenses between $697 million and $707 million, GAAP earnings of $0.93 and to $1.02 per share and non-GAAP earnings of $1.50 to $1.55 per share. As we announced in December, we are raising our long-term financial objective to manage to a Rule of 45 model over the next several years. We'll achieve this through a combination of solid revenue growth and non-GAAP operating margin expansion further beyond 30%. We're reiterating a strong outlook for the year and executing to our plan is an important step towards that objective. At the same time, we continue to work through our long-term planning process, and we'll provide additional details as we have in the past, once that process is complete. In conclusion, we delivered a very good start to the year. We drove double-digit revenue and earnings growth and generate strong cash flow. Our ongoing focus on managing the business for sustainable long-term growth has served us well. While steadily expanding profitability, we continue to invest in the critical next-generation technologies driving our customers' momentum. And we've prudently managed the strong cash flow we've generated through a balance of a balance of value-enhancing M&A and substantial buybacks. And with that, I'll turn it over to the operator for questions.\\nOperator: [Operator Instructions] And our first question is from the line of Mitch Steves with RBC Capital Markets. Please go ahead. Your line is open.\\nMitch Steves: Hi, good afternoon, guys, so obviously, a good quarter here. I just had a couple of questions. The first one is actually just on the guidance. I've got a model that goes back pretty far. I realize you guys haven't missed a quarter in something like a decade. But I guess, historically, when you guys beat the first quarter and guide up the second quarter, you usually take out the full year lease by the magnitude of the beat. So I guess why is that not occurring this time? And then secondly, just in terms of the Software Integrity business, can you maybe provide us an update on kind of how you expect the margins to trend? I realize that last year is probably a difficult year in terms of getting new business, but how should that kind of trend through the year? So those are my tow questions.\\nTrac Pham: Okay. And Mitch, this is Trac. Let me take the first question with regards to the guidance for this full year, and we definitely feel very good about the outlook for the year, especially in light of the strong quarter that we just posted in Q1. Now that said, it's still early in the year, and there's still a lot of business to book. And our focus is making sure that we execute in the guidance for Q2 and ensuring that we are on track to deliver very good growth and earnings growth for the full year. We've got a strong Q2 ahead of us, and we'll focus on that, and we'll provide more color on the year when we report in May.\\nAart de Geus: Regarding SIG, the good news is I think that we've made a number of changes where we are starting to see some of the positives. And for this year, our main objective was not so much to change the margins that to come back to growth rates that we can be more proud of. And so that is trending in the right direction. It's the first quarter, so it's a little early, but we're very encouraged. I'm also very encouraged because I can see and feel a change of tone in the team. I can see some very strong people have joined and so all of that is heading in the right direction. But as said, growth is our first objective because invariably, once growth does well, margin is much more manageable.\\nTrac Pham: Yes, I would add to Art's comment that it is a good start to the year. And as we resume growth in that business, over the long term, certainly, it's going to -- the leverage on that business is both a combination of very strong growth and margin expansion that should contribute to the overall margin story as well.\\nOperator: [Operator Instructions] We'll go next to the line of Jason Celino with KeyBanc. Please go ahead.\\nJason Celino: Thanks for taking my question. Maybe for my first one for Trac. You mentioned a little bit of pull forward in the quarter, very solid beat, but maybe could you just quantify maybe what the amount and what products?\\nTrac Pham: Jason, it's mostly on the hardware side. We saw hardware was a little bit better than expected for the quarter. And then with regards to IP, we had some IP deals that were scheduled in Q3 that we saw in Q1. That was an element of the quarter. But for most part, the results in Q1 were a function of really good execution across the board, and you can see that in the mix of how we did geographically and also by the different products.\\nJason Celino: Okay. And then for my follow-up, it looks like you've broken out China and it accelerated meaningfully in Q1 even from the whole year of last year. And even with limited data here, it seems to be kind of confirming your confidence in that China wasn't pulling. But I'm curious what specifically about Q1 versus maybe what you saw all of last year?\\nAart de Geus: Well, in simple terms, China is growing well as a high-tech country. And so there are many customers that are all doing more and more chips that are doing more sophisticated chips and that rely on our tools to get essentially as a growing economy that will continue to do well for a number of years.\\nOperator: [Operator Instructions] Our next question will be from the line of Jackson Ader with JPMorgan. Your line is open. Please go ahead.\\nJackson Ader: Art, you mentioned that the kind of recent breaches, specifically with solar wins has increased the awareness or the demand on consulting-led Software Integrity deals. But just curious on the product side, either from Tinfoil or the Black Duck products. Are these also seeing an increased demand? And is there anything that those products do specifically that might help this type of attack in the future?\\nAart de Geus: Well, our business tends to be not so much in the diagnostic of issues and more in the prevention of them. Now some of the products that you mentioned are sort of on the boundary of that. And to be honest, I don't know if these had any bump-up. In general, I would say that these type of breaches initially go through almost like a panic phase where people just want to find out, have they been breached and so on. That is not the business that we are in. Then they go into the longer-term considerations, which is how do they make their environment much more solid. And that is precisely where our Software Integrity group is focused on. And more often than not, this is why sophisticated consulting is a value because there are so many different product offerings in the world and plotting a strategy that over the long-term makes the development of environment stronger actually requires some sophistication. And so, that is why we're trying to staff up further in those areas because we do see that it has impact.\\nJackson Ader: Okay. Great. And then just a quick follow-up. Given the supply chain disruptions that we see in the automotive market, can track, can you just remind us how much of your maybe IP revenue is booked on royalties or product shipments? And should we expect to see any kind of headwinds from the automotive slowdown?\\nTrac Pham: Well, I'll start with the second part of the question. So far, we haven't seen a change in the momentum of the IP business. There's -- the IP business is pretty diversified. Obviously, automotive is a good segment and a good element of growth for that business. But so far, we're not seeing any impact in terms of the momentum that we've experienced over the last several years. With regards to the up-front mix, that's more a function of the fact that we switched over to 606 in 2019. And so you're going to see a little bit more up-front in the business, which will create more variability, but that's something that I think we've got some good experience over the last couple of years managing. So I don't see that as an issue. With regards to royalty, I don't have those numbers specifically in mind, but it tends to be a smaller portion of the overall revenue.\\nOperator: Our next question will be from the line of Joe Vruwink with Baird. Please go ahead.\\nJoseph Vruwink: I wanted to start. I was hoping to maybe get an update on where backlog finished the quarter. And relatedly, in recent quarters, you've been making some comments to suggest order trends being in line or better than your expectations. Just wondering, if we could maybe get an update on how new business, Trac, relative to your thinking at the story of the quarter.\\nTrac Pham: Joe, we backlog for the quarter ended at around $4.6 billion. And the bookings trend for the quarter was pretty much as planned. We did well in the quarter. Keep in mind that the backlog and the bookings will vary from quarter-to-quarter, depending on the large deals that are expected to be in that quarter. So it will vary. And what we typically emphasize more is looking at the quality of the deals that we closed in the quarter and whether or not run rate, what the trend on run rate was, and that was definitely higher this quarter.\\nJoseph Vruwink: Okay. That's helpful. And then are going back to the new product discussion between through the IC Compiler, DSO.ai and then SLM. Just wondering, over a mid-term framework, which of these things do you think has the potential to be more material to Synopsys performance? When you throw out DSO.ai becoming an anchor product for customers, are you demonstrating the type of PCA where that if we think a few years down the road, this is going to be a flagship like some of your other flagships? Or would you maybe point towards one of the other products in your discussion as being more influential to Synopsys revenues in the midterm?\\nAart de Geus: Well, of course, every team at Synopsis has its own preferred one, meaning the one they're working on. But you're certainly very correct to say that DSO is of high potential because but DSO really applies to some of our other flagships. And in the case of design automation, it uses a Fusion Compiler and a number of the tools that go with it. And so, they're in light its power because if you can amend the human with machine learning-driven enhancements and acceleration, then it's very similar to what we literally did 30 years ago when we came in to the market with automatic synthesis, where the human did a lot of work and the synthesis became essentially a power tool for them. And so, I expect that we will see impact of that already this year and certainly next year. If we look at 3DIC, that will be a little bit more gradual, but it's very fundamental because as you well know, a lot of people had predicted the death of Moore's law. And by the way, it's far from dead, but it has slowed down. And what is so interesting, in my opinion, with 3DIC is that that is another way to adding substantial complexity where instead of doing it all on one chip, you can do multiple complex chips and connect them very closely together. So over time, this will grow in importance. And then Silicon Lifecycle Management is particularly interesting because the word life cycle is in there. And that would tend to say, well, the utilization will be over a longer time frame, but the interest turns out to be extremely high already now because people see that if we could put a variety of data sources and intelligence inside of the chip for self-diagnosis, that's going to be rapidly more and more important for all the places where chips are used on applications that could engage our human life. And of course, the car comes up as the first example for that, but robotics and a number of other areas, we'll have the same. And so, what -- from our perspective is exciting about this, these are also very much organic innovations may be amended with some small acquisitions. And it bodes well for sort of the speed in which we are creating new value, and that's an additional reason to emphasize it to you.\\nOperator: And our next question from the line of Gary Mobley with Wells Fargo Securities. Please go ahead.\\nGary Mobley: Good afternoon everybody. Thanks for taking my question. I wanted to want to ask kind of the, I guess, intangible type question to Art, and maybe you have a good answer, maybe you don't. But one of the things that we've been hearing from fabless chip companies as they're struggling to get access to adequate manufacturing capacity, in particular, leading-edge process nodes. Is that there really seems to be less of a hurry to develop the latest and greatest sub-5-nanometer chip? And so my question to you is, have you seen any slowdown or any feedback from customers indicative of perhaps a slower pace of design innovation in light of the capacity constraints the chip industry is seeing?\\nAart de Geus: Okay. I do think I have a good answer for that. For starters, on the advanced nodes, we see none of that on the contrary. I think the race is fully on. A lot of companies understand that the impact of, let me call it, AI-enhanced computation is going to be enormous on a lot of end markets, and those are sophisticated chips. And a lot of people are essentially chasing that opportunity, all in the hope of having the best offering. And so, no slowdown as far as we can tell, and I emphasize in the preamble, the many new technologies we have precisely because that is of high appeal. I think part of the confusion around the capacity question comes from the fact that the automotive industry, which is hammered right now by essentially the lack of a few parts in order to ship a car, it's really quite pathetic because these are little parts And they hold back a high value product, is actually mostly in older technologies and in older manufacturing and so not even 300-millimeter but the smaller wafer sizes. And for those, there's not really an alternative because there's a limited number of these foundries. And sure, you could redesign these chips, but who wants to redesign these old chips just because right now, for a couple of months, you don't have enough parts. And so that is the picture that we see. I expect that, that will go away in a few months. But nonetheless, meanwhile, if you're caught in essentially the supply chain narrow spot, you can see the impact. And so over time, I think what we will see is that a number of companies will become more careful in saying, hey, if I have to move this design to a newer technology, I want to design it already now so that it's better documented and can be essentially remapped to a new technology.\\nGary Mobley: Okay. Appreciate the thoughts there. As my follow-up, I want to pin you down a little bit pin you down on a little more detail related to Software Integrity. If I go back to your last earnings call, I think you guys were mentioning that perhaps you can generate 15% to 20% bookings growth in the current fiscal year, which would ultimately end up translating to that similar growth rate in the out-year let's call it, fiscal year '22. Just to pin you down here on that. Is that reaffirming today given the start of the year?\\nTrac Pham: Yes, Gary, that's what we're reiterating.\\nOperator: [Operator Instructions] And our next question from the line of Jay Vleeschhouwer with Griffin Securities. Please go ahead.\\nJay Vleeschhouwer: Art, let me start with you with a question concerning the breadth of growth in core EDA, then a follow-up for you, Trac. So for Art, it's been quite obvious for the last number of years that there's been a rejuvenation of growth in synthesis and as well in implementation for obviously benefiting you in those two areas. But industry data and just the logic of technology would suggest that there was a close correlation between synthesis and the usage of RTL simulation, where you're also a market leader and then similarly for implementation correlated to DFM and physical verification. The question therefore is, has the growth -- the better trajectory you've seen in both DC and implementation induced more rapid growth as well in those highly correlated technologies and products. And then for Trac, how are you thinking about your head count growth for the year in the context of your OpEx guidance for fiscal '21? At the end of the quarter, you had what appeared to be a record number of openings, equivalent to over 6% of head count. So maybe talk about how you're thinking about the rate of bringing people on. And then frankly, if you are having issues with availability, given the large numbers that you have in your open recs as do your two large competitors?\\nAart de Geus: Okay. Jay, the question you're asking is complex because fundamentally, the picture that you're painting is a picture that started with individual tools and had long moved towards tools that are very correlated with each other and often used in tandem. And so a number of years ago, I point the term that we're moving from scale complexity more of the same to systemic complexity, which is more of the same plus heterogeneous demands and constraints all coming together. And so, if you take as I said of gravity like you did in synthesis and implementation and you look upward, you arrive at RTL, which is essentially a way to describe hardware, but RTL does very much look like a language, and that's not a surprise because right on top of that, sits software. And so we very much see a cone upward that's broadening where hardware and software and hardware-software together to be verified and optimized, and this is increasingly the case for all the large systems. And by the way, around the software for simulation, we added a variety of hardware accelerators such as emulation and prototyping. If you look downward, you mentioned DFM, which stands for design for manufacturing. And that is an absolutely correct term because the manufacturing, which was nicely isolated, somebody else was worried about the physics, as you go to smaller and smaller things, you have to worry about a lot of things when you design a chip. And so the connectivity down to the manufacturing has grown substantially, and we do ourselves way more there. But aside of manufacturing, I could have added the word test because we also do design for test. You have now heard the Silicon Lifecycle Management, which is sort of designing for what happens later. I could have added to word FUSA, functional safety because for all the cars, there are all kinds of rules that one has to follow, and we have actually a fabulous offering in that. That is, by the way, also manifested in the IP. And reliability is going to grow in importance as well for all of these products. So for a long time, we have always looked at this as the big picture. And the complexity of these intersections is actually one of the areas where Synopsys shines. And that's precisely why I mentioned in the preamble a few times that the benefit of the cross-discipline is something that where we can really add a lot of value to our customers. And I think that will continue.\\nTrac Pham: Hi, Jay, this is Trac. So I want to make sure I understand your question correctly. You're asking about head count growth and how that matches up with our expense guidance for the year and therefore, margin for the year, is that correct?\\nJay Vleeschhouwer: More or less, yes, I mean you're clearly looking to bring on a large number of people. If you were to fill every one of your open positions today, would you stay within the range of OpEx guidance, for example?\\nTrac Pham: I don't want to comment about the rec itself, but in general -- generally speaking, the business. And that's consistent. The investment that we're making in the business is consistent with the goal of increasing margins to the 29% to 30% for this year. In addition to that, that investment is also related to our long-term goal of driving to the Rule of 40, 45, which is going to be making sure that we continue to grow the business over time and also expanding margins simultaneously, so the head count itself is really a commitment to a balanced commitment to drive growth and improve profitability.\\nOperator: Our next question is from the line of Pradeep Ramani with UBS. Please go ahead.\\nPradeep Ramani: I had a couple of questions on China. I mean, your revenue is growing 74%, I guess, year-over-year, but when I look at a company level, your time-based revenues are growing 13% to 14% year-over-year and up-front grew 15%, 16%. So I mean is my interpretation correct that with regards to the mix in China with respect to EDA or hardware or IP, it is more or less in line with your mix overall? Or are you sort of -- or is the mix sort of skewed more towards EDA or hardware both in terms of absolute revenue dollars and growth?\\nAart de Geus: Well, let me take it from the product side. China, of course, came online, roughly speaking, 25 years after most of the west. And so when they entered the space of starting to do, let's say, significant chips, not the really small things, but of some meaning, right away, they entered with a design methodology that was more up-to-date than what some of the other companies use. And so that predicated from the start a substantial amount of IP being used in parallel to the advanced technologies. And so from that sense, the balance is slightly different than in the traditional west if I can call it that. At the same time, increasingly now all of these companies look the same to us be it China, be it in Korea or in Europe or in the U.S. All the ones that are driving the state of the art have to deal with the physics underneath have to deal with the software on top and have to deal with the sophistication of large IP blocks and substantial development capabilities. And so, while it was more different, maybe a decade or so ago, I think it is now more the same than it was before. And in hardware, I think it's sort of a very similar picture. The most advanced users are the people that are sitting at the intersection of hardware and software, and that is precisely where Synopsys shine.\\nPradeep Ramani: Okay. And for my follow-up, I guess, if I look at your -- again, the China revenue, how do you think -- how are you looking at it in terms of -- as you progress through the rest of the year? I mean, do you get a sense that, obviously, it's going to grow faster than last year overall? Or are you sort of seeing the comps get harder in the back half and sort of de-selling a little bit?\\nAart de Geus: Well, I would say last year was a strong year for us as well. And so in general, as you well know, the Chinese economy did actually grow in contrast to some of the western economies. The hope, of course, is that the west will start to grow as COVID gets hammer down more. But in general, there's no reason to believe that China will not continue to be a very live market for us. And in general, I would say, overall, everything touching chips and around it right now is doing well because of the overwhelming demand of all the end markets and the specialized verticals.\\nOperator: [Operator Instructions] Thank you and I have a follow-up question from Pradeep Ramani. One moment, Pradeep, your line is open. Did you have an additional question or should we move onto a next person in the queue? Okay, I am going to release that line. We're going to go next to the line of Vivek Arya with Bank of America Securities.\\nVivek Arya: Thanks for taking my question. Art, I'm curious, are you seeing more customers design with ARM technology in the PC and the server markets? How would you think about that trend now versus what it was in the last one or two years? Any way to kind of quantify whether it has gone up or down?\\nAart de Geus: It's hard to quantify if there are more, but it is easy to quantify that they have progress, meaning that already a number of years ago, and it was more than two years ago, a number of people started to look at, is it possible to use ARM cores for -- in the surface space. And some have continued to try. Others have given up at that time. But now, there's definitely a small group that is looking at using the service actually in cloud environment. And I don't want to announce who these people are. Some have probably spoken publicly at this point in time. But that has followed a lot of hard work to make that possible. And now the question will be, are the economics and the capabilities sufficient to be a good counterweight to the x86 family of processes that are typically used in the cloud. So, it is well possible that we're actually going to see a further diversification of computation largely because cloud is not only the regular general purpose computation, but now we have specialized efforts, certainly, in everything dealing with big data and machine learning. And for that, clearly, a number of players have put processes on the market that are dedicated to that and are particularly fast for it. And so ARM fits into all of these categories that -- but so are a number of other people doing their specialized processes.\\nVivek Arya: Got it. Very helpful. And then for my follow-up, Trac, just two clarifications, I think you mentioned somewhere that some shipments moved into Q1. I was wondering, how much did they impact sales and EPS? And part B of that is, you've given a full year outlook of about 10% or so growth at the midpoint, I believe. What is the implied growth in the Software Integrity part of your business as part of that 10% growth for the full year? Thank you.\\nTrac Pham: Okay. So the first part of the question is that -- I'm sorry, was...\\nVivek Arya: The shipments moving into Q1, I recall you said something along those lines?\\nTrac Pham: Yes. There is some IP that should shift in Q1 that was originally planned for Q3, but overall, it was on a significant amount. Most of the quarter was really strong execution. With regards to the SIG, Software Integrity business, what we had commented on at the beginning of the year was that we expect to grow bookings by over -- in that 15% to 20% for the full year. And that with the time-based model that we have on revenue that we would exit the year at double-digit growth. But for the full year, we'll probably be in the high single digits. And so far, we are -- after Q1, we are on track for delivering that.\\nOperator: Our next question is from the line of John Pitzer with Cr\\u00e9dit Suisse. Please go ahead.\\nJohn Pitzer: First one, Trac, just going back to the OpEx guide for the year, maybe another way to ask an earlier question, was there anything about the COVID environment that hindered your ability to actually bring people on board to actually accelerate growth in some of the markets like Software Integrity, such that if we get to a point where the vaccine is widely distributed and things open back up, you guys might take that opportunity to kind of reaccelerate OpEx for future growth? Or how do I think about the COVID dynamic within OpEx? And then I have a follow-up.\\nTrac Pham: Yes. Overall, I think we've done a pretty good job of bringing head count on and breaking people on board. As a matter of fact, you bring up the topic. We brought our general new general manager for the Software Integrity business on without ever physically meeting him. So, it's something that we're managing through and much like the rest of the business, we're just learning how to work remotely and adapting pretty well, I think. And I think that we'll continue to do that throughout the rest of the year and adjust as things free up or change with the health environment.\\nJohn Pitzer: That's helpful. And then, Art, as my follow-up, just in the core EDA business. I'm wondering if you could help me just better understand how the business is tracking between sort of some of the more traditional customers you've had in that business. Let's call it, the Intels, Qualcomms and Broadcoms of the world and maybe some of the more nontraditional customers, the hyperscale companies, we now have a very vibrant private semi market that we haven't had in years. I'm kind of curious that nontraditional bucket. How big is that now part of the core EDA business? And I'm assuming it's growing meaningfully faster, but can you help me differentiate?\\nAart de Geus: Sure. Well, first, I think your description fits well, the situation, meaning the traditional big players continue to invest heavily because they are chasing or driving, depending how you look at it, advanced technology, no matter what. Secondly, the hyperscalers are clearly continuing to see the opportunity to do more designs themselves to do more manufacturing, not so much manufacturing, but control where they get their own products from. And the one thing that's different about hyperscales versus other companies, they don't design chips to sell the chips. They design chips in order to use them in their own product offering. Having said that, a number of these companies have been successful already at doing that. Some have acquired small start-ups and some are literally growing their design teams and their experience to go with it as we speak. And so, it's a part of the market that is definitely on very good growth, I would say, probably twice as much as the rest. And then the other category, you call them start-ups, sometimes we also call them all AI companies or machine learning-ish companies because there are many companies around that and not that they all do AI processors, but there's a vibrant world that is essentially trying to change the future. And so only anything that is close to machine learning is super highly interested at the minimum, two things, which is compute very fast and compute with a lot of data. And once you say these words, you have to also say not using too much power because otherwise you fry the chips. And so, those are all good words for us because that means, they tend to immediately heads towards the most advanced IP, head towards the most advanced utilization of tools. And so that has also been a very good market for us. So, some of the AI guys get acquired by the traditional list. Some of the traditionals get acquired by the hyperscalers. It's a live market. And live is a good word in here because this is a field where advanced change in technology opens new doors at the very moment where there are a lot of opportunities.\\nJohn Pitzer: And Art, I know it's early, but is there any way to size that nontraditional bucket as a percent of revenue today?\\nAart de Geus: Well, there is a way, but we don't do it for you, unfortunately. Sorry, we don't disclose the individual buckets. But I don't mean to be coy. I want to be very clear, I think hyperscalers, AI and a few other specialty areas are very good growth for us and are also very demanding, which is typically actually good for us because it drives angles of technology that will be meaningful. And while, for example, I did mention the whole automotive space because it tends to be a little behind on the most advanced technology, it is now looking very much forward precisely because of these needs of life cycle guarantees, reliability, functional safety, and a number of those concepts are very powerful and will, over time, I think, also make it back into the other groupings. So, I guess what I'm describing to you is a really live field, and our job is to find which ones of these customers are the nuggets and serve them as well as we can.\\nOperator: And with minutes remaining in our call, we'll take our last question in the queue from the line of Gal Munda with Berenberg Capital Markets. Your line is open.\\nGal Munda: Thanks for taking at the end. Appreciate it. And the first question is just around the EDA growth that you're seeing. Clearly, above what we used to say is kind of sustainable growth of the market, and you're referring to some significant market share wins that you're taking. I was wondering if you're able to kind of separate what you're seeing in terms of what the market is growing as recently considering the fact that there's been an acceleration in the general market trends. And how much is the market share win as in addition to what you're growing at when you're growing close to the double digits?\\nAart de Geus: Well, I think I'm always a little careful before commenting on competitors. And I do think that the overall market is actually strong as my response to the previous question. And so, I assume that all of us benefit from that. There's no question in my mind that in some of the advanced areas that we have focused on for the last few years and often communicated to you about, we are doing particularly well. And moreover, that we're building on top of that sort of next-generation capabilities that look very, very promising. So in that context, I assume that over time, we may gain some share. But this is always in the landscape that overall is positive, and we should continue to invest in these areas because now it's a good time for that.\\nGal Munda: Got you. And then just the last one. Going back to China, and if I look at that revenue run rate that you're on right now implying -- if you just extrapolate that around $460 million-ish of without any sequential growth of revenue, which is significant. How much of this China revenue in general would you classify as recurring? Is it similar to what you have in the rest of the business, similar percentage? Or is it more specific?\\nTrac Pham: Overall, the business mix in China is very similar to total Synopsys. We've been able to do very well across the board.\\nAart de Geus: Well, I guess, this brings us to the end of the hour. And so first and foremost, we hope that you and your families have been able to stay healthy and that in the light of coming vaccines, you have both the patience to protect yourself and get there as soon as possible. And also, thank you for your continued following of Synopsys. And for a number of you, we'll be following up in the next few hours in one-on-one calls. Be well.\\nOperator: Thank you. Ladies and gentlemen, this will conclude our teleconference. Thank you for using the AT&T conferencing service and you may disconnect.\",\n          \"Operator: Good morning, and welcome to Johnson & Johnson's Third Quarter 2023 Earnings Conference Call. All participants will be in a listen-only mode until the question-and-answer session of the conference. This call is being recorded. If anyone has any objections, you may disconnect at this time. [Operator Instructions] I would now like to turn the conference call over to Johnson & Johnson. You may begin.\\nJessica Moore: Good morning. This is Jessica Moore, Vice President of Investor Relations for Johnson & Johnson. Welcome to our company's review of the 2023 third quarter business results and full-year financial outlook. A few logistics before we get into the details. As a reminder, you can find additional materials, including today's presentation and associated schedules, on the Investor Relations section of the Johnson & Johnson website at investor.jnj.com. Please note that this presentation contains forward-looking statements regarding, among other things, the company's future operating and financial performance, market position and business strategy. You are cautioned not to rely on these forward-looking statements, which are based on current expectations of future events using the information available as of the date of this recording and are subject to certain risk and uncertainties that may cause the company's actual results to differ materially from those projected. A description of these risks, uncertainties and other factors can be found in our SEC filings, including our 2022 Form 10-K, which is available at investor.jnj.com and on the SECs website. Additionally, several of the products and compounds discussed today are being developed in collaboration with strategic partners or licensed from other companies. This slide acknowledges those relationships. Moving to today's agenda. I will start by reviewing the third quarter sales and P&L results for the corporation and highlights related to our two businesses. Joe Wolk, our CFO will then provide additional business and financial commentary before sharing an overview of our cash position, capital allocation priorities, and updated guidance for 2023. The remaining time will be available for your questions. Joaquin Duato, our chairman and CEO; John Reed, and Ahmet Tezel, our Innovative Medicine and MedTech R&D leaders, as well as Erik Haas, our VP of Litigation, will be joining us for Q&A. To ensure we provide enough time to address your questions, we anticipate the webcast will last approximately 60 minutes. As a reminder, on August 23, 2023, Johnson & Johnson announced the final results of the exchange offer and completion of the separation of Kenvue Inc. Unless otherwise stated, the financial results and guidance highlighted today reflect the continuing operations of Johnson & Johnson. We will report the consumer health financial results as discontinued operations. Additionally, going forward, the pharmaceutical segment will be referred to as innovative medicine. Starting with Q3 2023 sales results. Worldwide sales were $21.4 billion for the third quarter of 2023, an increase of 6.8% versus the third quarter of 2022. Operational sales growth, which excludes the effect of translational currency, increased 6.4% as currency had a positive impact of 0.4 points. In the U.S., sales increased 11.1%. In regions outside the U.S., our reported growth was 1.6%. Operational sales growth outside the U.S. was 0.7% with currency positively impacting our reported OUS results by 0.9 points. It is important to note that operational sales in Europe were negatively impacted by the COVID-19 vaccine and loss of exclusivity of ZYTIGA. Excluding the net impact of acquisition and divestitures, adjusted operational sales growth was 4.9% worldwide, 8.9% in the U.S., and 0.3% outside the U.S. Turning now to earnings. For the quarter, net earnings were $4.3 billion and diluted earnings per share was $1.69 versus diluted earnings per share of $1.62 a year ago. Excluding after-tax and tangible asset amortization expense and special items for both periods, adjusted net earnings for the quarter were $6.8 billion and adjusted diluted earnings per share was $2.66, representing increases of 14.1% and 19.3% respectively, compared to the third quarter of 2022. On an operational basis, adjusted diluted earnings per share increased 13.9%. I will now comment on business sales performance. Unless otherwise stated percentages quoted represent the operational sales change in comparison to the third quarter of 2022 and therefore exclude the impact of currency translation. Beginning with innovative medicine. Worldwide innovative medicine sales of $13.9 billion, increased 5.1% with growth of 10.9% in the U.S. and a decline of 2.3% outside of the U.S. Operational sales growth increased 4.3% as currency had a positive impact of 0.8 points. Excluding COVID-19 vaccine sales, worldwide operational sales growth was 8.2%, with growth of 10.9% in the U.S. and growth of 4.3% outside of the U.S. Sales outside the U.S., excluding the COVID-19 vaccine, were negatively impacted by approximately 500 basis points, due to the loss of exclusivity of ZYTIGA in Europe. Innovative medicine growth was driven by our key brands and continued uptake from a recently launched products with 11 assets delivering double-digit growth. We continue to drive strong sales growth for both DARZALEX and ERLEADA with increases of 20.7% and 27% respectively, due to continued share gains and market growth. Within immunology, we saw growth in STELARA and TREMFYA, with increases of 15.8% and 21.5% respectively. This growth was predominantly driven by favorable patient mix and market growth. Turning to newly launched products, we continue to make progress on our launches of CARVYKTI and SPRAVATO. We are also encouraged by the early success of our launches of TECVAYLI and TALVEY, sales of which are driving the growth and other oncology. We expect to begin disclosing TECVAYLI sales in Q1 2024. Total innovative medicine sales growth was partially offset by the loss of exclusivity of ZYTIGA and REMICADE, along with a decrease in IMBRUVICA sales, due to competitive pressures. I'll now turn your attention to MedTech. Worldwide MedTech sales of $7.5 billion increased 10% with growth of 11.6% in the U.S., and 8.3% outside of the U.S. Operational sales growth increased 10.4% as currency had a negative impact of 0.4 points. Abiomed contributed 4.6% to operational growth, excluding the impact of acquisition and divestitures, worldwide adjusted operational sales growth was 6%. On a pro forma basis, utilizing sales in the prior year from Abiomed as a standalone company, MedTech's growth for the quarter would be 6.4%. MedTech was negatively impacted across all platforms by international sanctions in Russia worth approximately 60 basis points in volume-based procurement in China, primarily in five MedTech platforms: Spine, Trauma, Endocutters, Energy, and Electrophysiology. As communicated last quarter, we saw the return to more normalized seasonality with moderate deceleration in the third quarter. The Interventional Solutions franchise delivered operational growth of 48.1%, which includes $311 million related to Abiomed. This reflects growth in Abiomed patient procedures in the high-teens and continued strong adoption of Impella 5.5 technology in surgery. Electrophysiology is a major contributor to this growth with a double-digit increase of 20.3%. This reflects strong growth in all regions, including Europe, driven by our global market leading portfolio, including the most recently launched QDOT RF ablation and OPTRELL Mapping Catheters. Operational growth of 3.2% in surgery was driven primarily by procedure recovery and strength of our biosurgery and wound closure portfolios. Growth was partially offset by the impacts of volume-based procurement in China and supply challenges. Global growth of 5.4% in vision was driven by price actions and contact lenses and other, as well as strength of new products including ACUVUE OASYS 1-Day family of products and contact lenses and TECNIS Eyhance, our monofocal interocular lens and surgical vision. Growth of contact lenses was partially offset by strategic portfolio choices and supply challenges, although these continue to improve. Global vision growth was negatively impacted by 100 basis points, due to the Blink divestiture. Orthopedics operational growth of 2.6% reflects procedure growth, success of recently launched products, such as the global expansion of our VELYS digital solutions, and expansion in ambulatory surgical centers, partially offset by the impacts of volume-based procurement in China in Spine and Trauma. Now turning to our consolidated statement of earnings for the third quarter of 2023, I'd like to highlight a few noteworthy items that have changed, compared to the same quarter of last year. Cost of product sold margin was flat due to favorable patient mix and lower COVID-19 vaccine supply network related exit costs in the innovative medicine business, partially offset by commodity inflation, unfavorable product mix, and restructuring related to excess inventory costs in the MedTech business. Selling, marketing, and administrative margins deleveraged 40 basis points, driven by increased expenses across the enterprise. We continue to invest strategically in research and development at competitive levels, investing $3.4 billion or 16.2% of sales this quarter. R&D was leveraged by 120 basis points, primarily driven by portfolio prioritization, partially offset by higher milestone payments in the innovative medicine business. Additionally, IPR&D impairments were $206 million in the third quarter of 2023. Interest income was $182 million in the third quarter of 2023, as compared to $99 million of income in the third quarter of 2022. The increase in income was driven by higher interest rates earned on cash balances, partially offset by higher interest rates on debt balances. The other income and expense line was an expense of $499 million in the third quarter of 2023, compared to an expense of $226 million in the third quarter of 2022. This was primarily driven by higher unrealized mark-to-market losses on public securities partially offset by the lower COVID-19 vaccine-related exit costs and lower litigation expense. Restructuring in the third quarter was $158 million, primarily related to the innovative medicine restructuring program announced in the first quarter. Regarding taxes in the quarter, our effective tax rate was 17.4% versus 16.7% in the same period last year. This increase was primarily driven by a non-deductible, non-recurring pre-tax charge that occurred in the current quarter. Excluding special items, the effective tax rate was 15.6% versus 15.9% in the same period last year. As a result of the completion of the exchange offer, Johnson & Johnson is presenting the consumer health business financial results as discontinuing operations, including a gain of approximately $21 billion. I encourage you to review our upcoming third quarter 10-Q filing for additional details on specific tax and separation-related matters. Lastly, I'll direct your attention to the box section of the slide where we have also provided our income before tax, net earnings, and earnings per share adjusted to exclude the impact of intangible amortization expense and special items. Now let's look at adjusted income before tax by segment. In the third quarter of 2023, our adjusted income before tax for the enterprise as a percentage of sales increased from 35.3% to 37.6%, primarily driven by favorable patient mix and innovative medicine, partially offset by unfavorable product mix and commodity inflation in MedTech. Innovative medicine margins improved from 41.4% to 45.4%, primarily driven by favorable patient mix and R&D portfolio prioritization. MedTech margins declined from 25% to 24.7%, primarily driven by commodity inflation and unfavorable product mix partially offset by a divestiture gain. This concludes the sales and earnings portion of the Johnson & Johnson third quarter results. I'm now pleased to turn the call over to Joe Wolk. Joe?\\nJoe Wolk: Thank you, Jessica, and thanks everyone for joining us today. This quarter's call marks a new era for Johnson & Johnson with a sharpened focus on Innovative Medicine and MedTech. What has remained consistent is our Credo and our commitment to patients. We are privileged to build upon our 137-year legacy of tackling the world's most complex healthcare challenges and helping patients with serious unmet health needs around the world. As we look forward, we are well positioned to grow our business and innovate across the spectrum of healthcare. We are excited about what's ahead and what we can achieve in the future. Before we dive into our performance, I want to briefly touch upon other items important to our business. The first is a brief recap of the Kenvue separation, which was formally completed during the quarter. The transaction was executed within our targeted timeframe and under budget, while generating significant cash and value for our shareholders. Through the separation, we raised $13.2 billion in cash proceeds through the Kenvue Debt Offering and IPO. We reduced Johnson & Johnson's outstanding share count by 191 million shares, or approximately 7%, without the use of cash and in a tax-free manner. We maintained our current quarterly dividend per share and we retained approximately 180 million shares of Kenvue stock that provides cash proceeds for future flexibility. We will see the full impact to EPS of the share reduction in 2024. Another item warranting comment is the Inflation Reduction Act. We continue to believe the IRA's price setting provisions are damaging to innovation and will prevent the delivery of transformative therapies and cures to patients. As we await adjudication of legal proceedings initiated by of us and others, we did submit all requested information in compliance with CMS' drug price setting scheme to continue supporting patients' access to our medicines that help them stay healthy and live longer. Moving to segment highlights in the quarter, as Jessica previously shared, our teams delivered strong results in the third quarter, while continuing to advance our pipeline to enhance future growth. Within the innovative medicine business, two important regulatory milestones were announced during the quarter. Specifically, we received European Commission approval for a reduced biweekly dosing frequency for TECVAYLI for eligible patients with relapsed and refractory multiple myeloma. And U.S. FDA and European Commission approval of TALVEY, a first-in-class, bi-specific therapy for the treatment of patients with heavily pre-treated multiple myeloma. Regarding clinical data, we are excited to have an unprecedented seven late breaking abstracts, including three featured in the Presidential Symposium being presented at the European Society of Medical Oncology meeting this weekend. Highlights will include the results from all three Phase III studies of RYBREVANT in lung cancer, including MARIPOSA, MARIPOSA II, and PAPILLON. Additionally, updated data from the Sunrise 1 study of TAR-200 in non-muscle invasive bladder cancer will be shared, as well as the first ever data of TAR-210 in patients with FGFR mutations. We also look forward to presenting Phase II data for Nipocalimab and rheumatoid arthritis at the American College of Rheumatology Annual Meeting in November, and have already launched a Phase II combination study NRA. Lastly, we plan to initiate multiple clinical development programs for our targeted oral peptide JNJ-2113. This includes the initiation of the ANTHEM Phase 2B study in ulcerative colitis, which will begin this month, and the Phase III clinical program titled Iconic for adults with moderate to severe plaque psoriasis expected to begin in November. Moving to MedTech, notable highlights in the quarter include significant advancements in electrophysiology across our cardiac ablation platform. We received FDA clearance from multiple atrial fibrillation ablation products in our portfolio to be used in a workflow without fluoroscopy. This FDA indication is unique to Johnson & Johnson and is a significant advancement where caregivers and patients are not exposed to harmful fluoroscopy-related radiation during their cardiac ablation procedures. It also allows for the removal of heavy lead protective equipment that may lead to orthopedic complications for care teams. In pulse field ablation, we have completed our clinical trial in Europe and submitted for CE mark for our VARIPULSE Catheter. We expect the completion for our U.S. VARIPULSE study to occur in the fourth quarter. We are also simultaneously advancing clinical studies for two additional pulse field ablation catheters, the STSF dual energy catheter, capable of delivering both PF and RF energy through the same device, and Omnipulse, a large tip focal catheter. Beyond electrophysiology, we have completed enrollment in the Abiomed Impella ECP clinical study, a landmark pivotal trial designed to demonstrate the safety and efficacy of the Impella ECP during high-risk PCI procedures. Impella ECP is the world's smallest heart pump and the only heart pump compatible with small bore access and closure techniques. While not a clinical advancement, we have also taken steps in the quarter to improve MedTech's future margin profile, implementing a restructuring program designed to simplify and focus the operations of our orthopedic business. As part of this two-year program, we expect to exit certain markets and product lines across that business. We anticipate some short-term modest revenue disruption in orthopedics of approximately $250 million in total over the next two years, given the market and product line exits, but believe these actions will improve our ability to meet demand, resulting in accelerated growth and enhanced profitability. The program is expected to be completed by the end of 2025, with total program costs estimated to be between $700 million and $800 million. Let's now turn to cash and capital allocation. We ended the third quarter with approximately $24 billion of cash and marketable securities and approximately $30 billion of debt for a net debt position of $6 billion. Free cash flow year-to-date through the third quarter was approximately $12 billion, up from the $5 billion we reported year-to-date in the second quarter of 2023. Our capital allocation priorities remain unchanged. We will continue to execute a strategic and disciplined approach utilizing our strong credit profile and robust free cash flow generation to prioritize continued investment in our business, increasing dividends on an annual basis, executing strategic business development initiatives for inorganic growth, and executing share repurchases when appropriate. Moving onto our 2023 guidance update. Based on the strong results delivered in the quarter and the first nine months of this year, balanced with planned investments in the fourth quarter, we are raising the ranges for full-year sales and EPS guidance. We now expect operational sales growth for the full-year 2023 to be in the range of 8.5% to 9.0%, or up $600 million at the midpoint in the range of $84.4 billion to $84.8 billion on a constant currency basis and adjusted operational sales growth in the range of 7.2% to 7.7%. Just a reminder, our sales guidance continues to exclude any COVID-19 vaccine revenue. While we do not speculate on future currency movements utilizing the euro spot rate as of last week at 1.06, we now anticipate an incremental negative currency impact of $400 million resulting in a full-year impact of negative 1% or $800 million. Looking across the P&L, adjusted pre-tax operating margin is still expected to improve by approximately 50 basis points versus prior year, driven by stronger margin profile and business mix. Net other income is also being maintained, ranging from $1.7 billion to $1.9 billion. Due to higher interest rates earned on our cash, we now expect net interest income in the range of $300 million to $400 million. And finally, based on current tax law, our estimate for the effective tax rate for 2023 will be between 15.0% and 15.5%. These revised estimates translate to an increase in our adjusted operational earnings per share guidance by $0.10 at the midpoint. Our new range is $10.02 to $10.08 or 12.5% growth at the midpoint, and adjusted reported earnings per share in the range of $10.07 to $10.13 or 13% growth at the midpoint. Since January, We've been able to increase our guidance throughout the year for a cumulative impact of $3 billion on operational sales and $0.25 on adjusted operational earnings per share, which includes absorbing $0.10 for our licensing deal with Cellular Biomedicine Group announced in the second quarter of 2023. Now I appreciate that many of you are turning your attention to 2024, and our teams are actively finalizing our plans for next year. With that context, allow me to provide some preliminary perspectives for you to consider. For innovative medicine, we remain confident in our ability to deliver growth from key brands and anticipate continued progress from our newly launched products, all while advancing our robust pipeline with many exciting data readouts, filings, and approvals ahead of us. This includes data presentations and regulatory submissions for TREMFYA in IBD, presenting data from our Phase III study of Nipocalimab in Myasthenia Gravis, and readouts from two Phase III or ELITA trials in early-stage prostate cancer. We do not expect the entry of STELARA Biosimilars in the United States during 2024. However, as a reminder STELARA does have a composition of matter patent expiry in mid-2024 in Europe. For MedTech, we expect our commercial capabilities and continued adoption of recently launched products across all MedTech businesses will continue to drive our growth and improve competitiveness, while continuing to advance our pipeline programs, including innovation in pulse field ablation, Abiomed, and surgical robotics. We expect procedures in 2024 to remain consistent with elevated 2023 levels. With respect to tax, as you may be aware, the European Union member states are in the process of enacting the EU's Pillar 2 Directive, which generally provides for a 15% minimum tax rate as established by the OECD Pillar 2 framework. The first EU effective date for certain aspects of the law is January 1st, 2024. As a result, we currently estimate it up to a 1% tax rate increase in 2024. In addition, the U.S. Treasury's current perspective on Pillar 2 will be harmful as it relates to the treatment of U.S. incentives for innovation and will result in U.S.-based multinational companies paying more tax revenue to foreign governments. Regarding share count given the Kenvue separation, the full benefit of the approximately 191 million net share reduction in Johnson & Johnson shares outstanding from the exchange offer will be reflected in our 2024 financials. And finally, while we don't speculate on future currency impact, utilizing the current euro spot rate would yield an approximate $0.15 negative currency impact on 2024 full-year adjusted earnings per share. We are pleased with our strong performance during the first nine months of this year and have positive momentum as we move into 2024. We look forward to sharing more about the strength of our business, promise of our innovative medicine and MedTech pipelines, and the long-term strategy of Johnson & Johnson at our upcoming Enterprise Business Review on December 5th at the New York Stock Exchange. More information, including an overview of the day's schedule, will be shared shortly. We hope you will be able to join us either in person or on the available webcast. I want to conclude my remarks by thanking our teams around the world for their continued hard work and unwavering commitment to excellence on behalf of our patients. We are confident that our strategy will position us to deliver long-term growth and create significant value for our shareholders. With that, it's my pleasure to turn to Kevin and begin the Q&A portion of the call.\\nOperator: Thank you. [Operator Instructions] Our first question is coming from David Risinger from Leerink Partners. Your line is now live.\\nDavid Risinger: Thanks very much for taking my question and congrats on the strong financial performance. So my question is on benchmarking MARIPOSA results, please. Could you share your thoughts on key considerations, including AstraZeneca's recent FLAURA2 results, which included a nine-month PFS benefit? Thanks very much.\\nJohn Reed: Hi. John, Reed here. It's great to join the call. This is my first time as a newcomer to J&J, and before I answer your question, David, I would just like to say I have to tell you I'm really enjoying being a new member of the J&J team. I've really been impressed with the culture inspired by our Credo with the caliber of our talent our people here at J&J and with the really strong performance of the pipeline. We've already launched two NMEs this year, Akeega for prostate cancer and TALVEY for myeloma, continuing our tradition in bringing new therapies in those agents, and we're positioned to deliver an average of more than two enemies per year between now and the close of the decade 2030. So the pipeline is very robust and it's exciting to be here and to be a part of it. So on to your question, the data will be presented at ESMO in a Presidential session. So we're embargoed until then. Abstracts will be available on [Wednesday] (ph). I can only say that the RYBREVANT Lazertinib combo did perform well head-to-head against Osimertinib. Our regimen is a chemo-free option for patients, which we think is important, and we'll present those data at ESMO.\\nOperator: Thank you. Next question today is from Matt Miksic from Barclays. Your line is now live.\\nMatt Miksic: Hi, thanks so much for taking the question. So I think most folks may look at the orthopedic results in medical devices as maybe being a little bit softer-than-expected. And I know that's not everything by a long shot for J&J, but given the expectations for continued strength heading, I think, into Q3, if you could talk maybe a little bit about your comment on more traditional seasonality and thoughts on the sustainability of that strength, as well as the sort of divestiture and sort of realignment plan, Joe, that you described. Thanks.\\nJoaquin Duato: So thank you for the question. And yes, I mean, our results in orthopedics were 2.6% growth overall. And part of it, as you mentioned is driven by seasonality. As we have commented, we are in a journey of improvement in orthopedics. We want to be number one and number two in every segment we compete. And that is a place where we are not there yet, but we are very confident that we are going to continue to make improvements by investing and by growing in the highest growth segments. We have made improvements in our portfolio, for example, on the knee side. We have a more complete portfolio now on the revision side, on the cementless side. We are launching now our VELYS orthopedics total robot, total knee surgery replacement in Europe. And we already have about 30,000 procedures that have been performed with our VELYS robotic system. Overall, we are increasing our penetration also in the ASCs, which is a fast-growing segment, and we see our performance continue to improve in the U.S. and globally. In this particular quarter, we also had some impact due to the impact of value-based procurement in China and also because of the impact of the Russia sanctions that was mentioned already in the previous remarks. So overall, in orthopedics, we are determined to continue our journey of improvement. We are focusing in having the right portfolio. We have a very strong team in the field, and as Joe has announced, and Joe can comment on that, we have a plan to be able to continue to improve our margins in orthopedics.\\nJoe Wolk: Yes, just very quickly, Matt, thanks for the question. With respect to the restructuring program that we announced specifically in orthopedics, we're looking to exit those less profitable markets and product lines. So we'll have some clearly inventory write-downs as a result of that. Over the next two years, there will be some modest revenue disruption, but we actually do think these actions not only accelerate growth going forward, but will improve profitability.\\nOperator: Thank you. Next question is coming from Chris Shibutani from Goldman Sachs. Your line is now live.\\nChris Shibutani: Great. Thank you very much. Can you provide us with some insight into updates on the TALC litigation process? And then secondly, if you could just comment, Joe, you used the word voracious last time with your appetite for business development opportunities. How does that word stand still in terms of your appetite on the floor? Thank you.\\nJoe Wolk: Hey, so Eric, why don't I turn it over to you to discuss the TALC litigation matter and then I'll come back and answer Chris's second question.\\nErik Haas: Great. Thanks, Joe. The short answer is that we continue to pursue the four-pronged strategy that we communicated back in July. So let me quickly summarize those four prongs and highlight the salient developments and perhaps anticipate some follow-up questions about TALC. So the first prong, we are pursuing the appeal through to the Supreme Court of the United States of the July ruling by the New Jersey Bankruptcy Court that dismissed LTL's bankruptcy case. Notably, our appeal recently was joined by counsel representing the vast majority of the TALC claimants. Also, thereafter, the bankruptcy court certified the case for a direct appeal to the third circuit, bypassing the district court, because the bankruptcy court found that the appeal raises matters of significant public interest, the resolution of which would material advance the progress of the case and we fully agree with that assessment. The appeal challenges both the validity, as well as the application of the novel standard that was imposed by the third circuit that requires a showing of, \\u201cimmediate financial distress\\u201d to proceed with the bankruptcy case. That immediate financial distress requirement, which the third circuit did not specifically define, is nowhere in the bankruptcy code and is contrary to the standards that are implied -- employed by other circuits. Moreover, under any reasonable interpretation of that standard, we believe the record has fully established that LTL faced immediate financial distress due to the large volume of TALC claims that were asserted against it. In terms of timing, the third circuit could rule at any moment whether it will take the direct appeal or not. If it does, we expect briefing to take place over the next couple of months with a decision in the early 2024 timeframe. And because we do anticipate the third circuit will primarily affirm the application of its standards, we will immediately thereafter request the Supreme Court to resolve the circuit split and decide if the third circuit's novel approach is an appropriate standard for deciding a motion to dismiss. We do not think it is. We hope to squeeze the cert petition to the Supreme Court into the first term in 2024, but if not, we will raise it in the second term. Working with the council, representing the vast majority of the TALC claimants more than we had previously that were along with us. Along with the -- in addition to the future claims representatives and together with the council and the future claims representatives were pursuing a consensual resolution of the TALC claims through another bankruptcy. And that is exactly what the bankruptcy court, the New Jersey bankruptcy court urged and strongly recommended that we do in its decision that actually dismissed the case. And the New Jersey court made those recommendations having found that LTL had made remarkable progress towards an equitable and efficient resolution to-date. So we are continuing on in that process. In terms of timing on the second prong, the consensual resolution is on the same trajectory as the initial bankruptcy plan with a vote expected in the next six months to determine whether the requisite super majority of claimants support the plan. Third, while those negotiations are proceeding, we will continue to vigorously defend the meritless TALC claims in the tort system. As you may have seen just this last week, we had a significant favorable ruling in that regard with the New Jersey's appellate court in the Barden case reversing a $223 million verdict against the company. The appellate court reversed because it determined the opinions of the leading plaintiff's experts were unsound, were unscientific, and were unsubstantiated. And it is that baseless nature of those expert opinions why we have prevailed in the vast majority of the cases that have been tried to-date. In terms of timing of the litigation, there are two additional mesothelioma cases that we expect will be tried this year with more to come in 2024. As with the Barden case, it's important to keep in mind that the ultimate resolution of those matters often is determined at the appellate level, not at the trial level, which is the place which occurs in the forms that the plaintiff lawyers choose. Finally, we will aggressively challenge the abuses of the judicial system by the mass tort plaintiff's bar and its experts with their own affirmative litigation. We mentioned last time that we brought two actions against the plaintiff's bar's lead experts for defaming our TALC products with publications premised unknowingly false propositions. And those are moving forward. They've been fully briefed with respect to the initial case motions and in terms of timing, we expect a ruling shortly from the Federal District Court in New Jersey, whether those matters may proceed to the discovery phase. So that's a quick summary. I'd be happy to answer any follow-up questions you may have regarding the strategy.\\nJoe Wolk: Great. Thank you, Eric. Chris, regarding your second question, you know, if J&J had a nickel for every time voracious was quoted back to me since the second quarter earnings, we probably could have taken up guidance even a little bit more. And while that's often associated with wanting or devouring great quantities, I think it's really the second definition in webster's where having a very eager approach to an activity is the construct in which I meant that term in the second quarter. So I could have said that five years ago, 10 years ago, my predecessors could have said that. We routinely, almost weekly meet on new opportunities that may complement our existing portfolio or our future pipeline in both MedTech and Innovative Medicines. And the current moment is no different. In fact, we're in a very good position, given the low levels of net debt, the cash we were able to raise to fulfill one of our capital allocation priorities, which you're probably very, very familiar with at this point in time. But we're not going to compromise our principles in making sure that it's a strategic fit. So it fits into the scientific expertise, the commercial capabilities, or the global reach that will add value to that asset in our hands versus someone else. And we're going to make sure that we're disciplined in that approach financially by ensuring that we have a return that's commensal with the risk that we're bearing on behalf of shareholders. So we'd much rather have an okay deal pass us by, then make a bad deal. And that's kind of the principles that we'll live into. There's no deal that's too big, give it our credit rating, as well as our financial strength and annual cash flow generation. But as you know, we've had great success doing smaller, earlier-stage deals as well. We're agnostic with respect to whether it\\u2019d be the next one being MedTech or Innovative Medicines, we are simply looking for the best qualified deal that meets both strategic and financial parameters. So hopefully that answers your question. Next question, Kevin?\\nOperator: Our next question is coming from Geoff Meacham from Bank of America. Your line is now live.\\nGeoff Meacham: Hey, guys. Good morning. Thanks so much for the question. I'll stick with one. So on CARVYKTI, can you talk about the commercial backdrop, just with respect to new centers or prescribers and related on manufacturing? You guys have any update on the vector constraints and maybe when that could be relieved? Thank you so much.\\nJoaquin Duato: Thank you, Geoff. And as you have seen in the progression quarter-over-quarter of CARVYKTI, we continue to have on one hand strong demand and on the other hand, progress in our manufacturing. We're also very encouraged by the data that came out with CARTITUDE-4 that eventually we make CARVYKTI also a medicine in early absence of therapy. So when it comes to our manufacturing progress, I'm going to let John explain what are we doing in order to be able to supply the strong demand that we are seeing in CARVYKTI today. Overall, what you can expect, Geoff, is that we -- you will continue to see quarter-over-quarter improvement in 2023 into also 2024.\\nJohn Reed: Yes, to follow up on Joaquin\\u2019s comments, we've been progressively adding more and more capacity. That's included at our original launch site in New Jersey, but we're close to having an additional manufacturing site up and rolling in Europe, in Belgium, and also have recently increased our capacity by using some excess capacity that Novartis had to further bolster the number of slots that we can accommodate. One of the traditionally rate-limiting components of the therapy has been the lentivirus component, and there we've made really outstanding progress in-house, mastering that technology, increasing the scale at our factory in Switzerland. And we're in the process -- we're building, I think it will be available next year, another factory in the Netherlands to support the lentivirus component, which has sometimes been one of the rate limiting aspects. So altogether the capacity continues to ramp up and we continue to perfect the technology I would say. Same thing with the number of centers that are qualified to administer the therapy and we're also making progress on the number of countries where CARVYKTI will be available. So very excited, obviously, about the momentum with that. Really, that best-in-class CAR therapy, the CARTITUDE-4 data as you know, showed unprecedented progression-free survival benefit, a hazard ratio of 0.26, overall response rate of 99%, 86% complete response. Very durable for a one and done therapy that was well tolerated. The Grade 3 or above cytokine release syndrome was only 1.1%. So this is really, I think, now emerging as the preferred second line therapy. And we hope to do more such as bringing the front line as a possible alternative to stem cell transplant.\\nJoaquin Duato: And, you know, Geoff, to your point, in multiple myeloma new product launches, we are also very encouraged by the launch of TECVAYLI and also the recent appointment of TALVEY. The progression of these medicines is exceeding our internal expectations and we already have about 2,000 healthcare professionals in the U.S. that are REM certified to be able to administer TECVAYLI and TALVEY. So very encouraging progress in these two medicines in multiple myeloma. And we expect to be able to break out TECVAYLI sales beginning in 2024.\\nOperator: Thank you. Next question is coming from Josh Jennings from TD Cowen. Your line is now live.\\nJosh Jennings: Hi. Good morning. Thanks for taking the questions. I was hoping to ask on STELARA and the biosimilar competition in the U.S. now expected in 2025. That's not new news, but I wanted to check in on how beneficial is the extra year for the innovative medicine and businesses defense strategy. I guess focusing on just the potential for TREMFYA to take share from STELARA and psoriasis and psoriatic arthritis and inflammatory bowel disease indications? And does this time make sure you provide more confidence and potential to hit the constant currency revenue target set for 2025 for the pharma unit? Thanks.\\nJoaquin Duato: Thank you for the question. Certainly we have always been very confident in being able to hit our $57 billion target in 2025 for pharma. As I have explained before, there are a number of factors there, the first one and most important is the growth that we're having in our key assets, TREMFYA, ERLEADA, UPTRAVI, our long-acting injectables, and especially DARZALEX, we continues to have a tremendous trajectory gaining share in first line. We are encouraged, as I just commented, by the launches of CARVYKTI, the progression of SPRAVATO, and also the recent launches too, also in multiple myeloma of TECVAYLI and TALVEY. And looking into 2024, the remainder of the year, and also into 2025, we have some very exciting news in our pipeline. Some of them have been already commented. For example, the first chemo-free regimen as first line in EGFR mutated non-small lung cancer. We will be presenting the data of MARIPOSA in our ESMO and that potentially will be a filing and an approval in 2025. This would be a new standard of therapy in this line of therapy in this very important need for patients. We also continue to be encouraged by the progress in our TARIS drug delivery platform. You are also going to see data being presented at ESMO. Very important for us in two existing products. We will be presenting data on TREMFYA in IBD, both in Crohn's and in ulcerative colitis for a potential approval later in 2024, that\\u2019s going to be a very significant growth driver for TREMFYA, take into consideration that in the STELARA case, IBD represents 75% of the sales. So we still have a lot of growth in front of us with TREMFYA, as we do also in ERLEADA, in which we will present data in localized high-risk prostate cancer. We also, you know, we're also going to be able to present some data of Nipocalimab in Myasthenia Gravis end of this year. So all in all, very good news for our pipeline in 2024 and 2025. Certainly, the entrance of the biosimilars in 2025 in the U.S. is another factor that builds our confidence that we are going to be able to meet the $57 billion. For me the most important thing now is to look forward and to think about the growth profile of our innovative medicine group into the second-half of the decade. We have a number of growth drivers that are already there that I described, but also the strength of our pipeline both in immunology, in oncology, and in neuroscience profiles us as a strong company, as a strong growth profile into the second-half of the decade. And that's part of what we will be looking forward to discussing with you in our upcoming enterprise with review, focusing on what is going to be the growth profile in the second-half of the decade.\\nOperator: Thank you. Next question is coming from Chris Schott from JPMorgan. Your line is now live.\\nChris Schott: Great. Thanks so much for the question. Maybe Joe, just a little bit more color on 2024. Appreciate the details you provided. Seems like a year of another healthy top line growth. But can you just give us some directional color on margins next year? I know there are some dis-synergies with Kenvue this year. I was trying to get a sense of how you think about margin progression here as you kind of balance some of these, you know, kind of, the pipeline opportunities and some of these top line growth initiatives versus, kind of, dropping that to the bottom line. So if there's any directional color, it would be appreciated. Thanks.\\nJoe Wolk: Yes, sure, Chris. Thanks for the question. So first off, we're very pleased with the margin progress that we've been able to make in 2023. I think we started the year to roughly flat to now improving by 50 basis points. A lot of that has really gone, is it directly attributable to the efforts of many people in the organization, who really took the opportunity to look at our infrastructure as a two segment company versus a three segment company. So dis-synergies that we warned about and talked about early on in the Kenvue separation process really haven't come to manifest. In fact, as we look out to 2024, we see minimal to almost no impact from dis-synergies from the separation. We are in the process of finalizing our business plans for 2024. I'd like to get a little bit better assessment of how the clinical development pipeline is shaping up, what the investments are required there. But we're a larger company. We take the opportunity to look each and every year at efficiencies. So we're not in a position to give you margin guidance right now, but I would expect that something similar to where we started this year would not be a bad starting point for next year. Again, it's going depend on the investments that the R&D teams from both MedTech and Innovative Medicines can bring forth, and we'll obviously look to accelerate bringing some of these great products to patients sooner if we have that opportunity.\\nOperator: Thank you. Next question is coming from Larry Biegelsen from Wells Fargo. Your line is now live.\\nLarry Biegelsen: Good morning. Thanks for taking the question. Joe, just -- could you just clarify what you meant by flat procedures in \\u201824 MedTech? Are you assuming, does that mean flat MedTech growth? And just for my question, can you talk about what you're seeing with bariatrics, if for GLP-1s this is, and how you're thinking about the potential impact of GLP-1s across your device business, you know, long-term, you know, especially in Cardio and Ortho. Thank you.\\nJoe Wolk: So I'll give the second half of that question to Joaquin, but thanks for the clarifying question with respect to market growth. We are not suggesting flat market, or a flat market in MedTech next year. What we do is, are foreseeing right now, based on what we know today, is the elevated levels, the market overall being 5% to 7% versus what traditionally has been maybe 4% to 6%. We see that same 5% to 7% next year. Joaquin?\\nJoaquin Duato: Thank you, and thank you Larry. And taking a step back, we see the evolution of our MedTech business in a very positive way. One of our key goals for us is to be a top tier grower in MedTech. When I look at the results of MedTech this year, we are delivering on that. Our growth in the quarter pro forma was 6.4% when you compare with Abiomed as a standalone company. And when you look at our pro forma growth year-to-date in MedTech is 7.9%. So very pleased with the performance of our MedTech business. And we have expectations to continue our progression into 2024, in part fueled by the procedural growth that we see and also, but our continued improvement in our execution and the launch of new products. Some of them we can discuss later. For example, you know, we will be launching our first PFA catheter in Europe into 2024. When it comes to GLP-1s, it's good for patients to have new options for treatment, especially in obesity, which at times has been a stigmatized disease in which patients were not looking for treatment due to the stigmatization of that. Certainly, as you commented, we're seeing some impact in our bariatric business in the short-term. Some patients are reconsidering surgery, expecting to get treatment. But overall, when we talk to surgeons, bariatric surgeons, what they see is a complementary role of surgery and GLP-1s, and many of them comment on the fact that they could see a tailwind for bariatric surgery down the road, given this complementary nature, the increased awareness about obesity, more patients seeking treatment, and many of the patients, about 30% of them, are not going to be tolerating this medication. So they would be another funnel for our bariatric business. In the rest of our MedTech business, at this point, we continue to see robust procedure increase and we don't anticipate that change, that thing -- that trend changing in the foreseeable future.\\nOperator: Thank you. Next question is coming from Terence Flynn from Morgan Stanley. Your line is now live.\\nTerence Flynn: Great. Thanks so much for taking the question. I was just wondering if you could elaborate a little bit more, John, on Nipocalimab in RA. I know we're going to see the full data here at ACR, but is this a drug that you see potentially working in a broad population or is there a biomarker subset group that's more likely to respond? And then how are you thinking about Phase 3 plans here in this indication? Thank you.\\nJohn Reed: Yes, thanks for the question and we look forward to sharing those data at the ACR in November in San Diego. We're looking at Nipo as either a monotherapy combined with a precision medicine strategy or as a combination for a broad population where we aim to combine with an anti-TNF agent. We see those two mechanisms as being very complementary, reducing the levels of auto antibodies with Nipo and then inhibiting inflammatory mechanisms with the TNF. The so-called DAISY study, the Phase 2, is underway now and we'll test that combination. So that in general has been the way we're looking at RA, not only for Nipo, but other agents in our pipeline where we see the future being monotherapies that are targeted in a precision medicine way or broad therapies that are combos that can bring together synergistic mechanisms in a safe way. We're excited to be launching the DAISY program to look at that combo. And we're hoping that that will bring deeper, more durable remissions for patients as we bring those new mechanisms together.\\nOperator: Thank you. Next question is coming from Joanne Wuensch from Citibank. Your line is now live.\\nJoanne Wuensch: Good morning and thank you for taking the questions. Is it possible to give us a little bit more detail on a couple of things? You mentioned headwinds from VBP and I'm just curious if there's, A, way to quantify it; and B, a way to say if it's at least better or worse or the same as it has been the last couple of quarters? And then similarly in other aspects of China, we've been hearing a lot about anti-corruption policies, et cetera. If you could comment on that, that would be great. Thank you.\\nJoaquin Duato: Thank you, Joanne. And first, let me say that China for us is a key market, and a market in which we are delivering growth now, and we are going to continue to deliver a strong growth into 2024. So it's a key growth driver for us. So on one hand, certainly, VBP represents a headwind in price. And on the other hand, it also represents an opportunity as you can expand quality products, medical technologies into more patients. So there are a number of MedTech platforms now currently undergoing VBP headwinds, electrophysiology, spine, trauma, endocutters and energy, and these effects will last during 2023 and part of 2024. We have already anniversary our large joins VBP. So at this point, we have about 80% of our platforms that have been already affected by VBP. Again, as we look into 2024, we expect to continue to deliver a strong growth in China, and China remaining a key part of our growth. When it comes to the question that you were asking in anti-corruption side, we have a strong culture of compliance in our business. And at this point, we may see some limitations related to physician and surgeon access, but we are not seeing any material impact in any part of our business due to that, and we'll continue to monitor the situation. Overall, as I said, we continue to see China as a key driver of our growth and also as a key source of innovation moving into the future.\\nOperator: Thank you. Next question is coming from Vamil Divan from Guggenheim Securities. Your line is now live.\\nVamil Divan: Great. Thanks for taking my questions. I just want to maybe dive a little deeper on the immunology side. Appreciate some of the comments you made there already with -- for the quarter, the performance was very strong for several of your products there? So I'm just curious if there were any sort of one-time items there that we should be aware of. It's under like there's a lot of patient mix and market growth that you are commenting on? I'm curious if you can just highlight any sort of stocking or sort of one-time pricing adjustments that we should take into account as we look at future quarters? Thank you.\\nJoaquin Duato: Thank you. We are very pleased with the performance of our immunology business, especially we're pleased with the performance of TREMFYA with 25.1% growth in the quarter, which shows our ability to drive growth there. As I said before, TREMFYA currently is now indicated in psoriatic arthritis and psoriasis as an analog. In the case of STELARA, that represents about 25% of the sales. So with the upcoming readouts, filing and potential approvals of ulcerative colitis and Chron's disease, we expect to have significant growth in TREMFYA. We talk about TREMFYA as a $5 billion product earlier in our Analyst Day in 2021. Now you can see clearly that we're going not only to meet that, but to clearly exceed that benchmark for TREMFYA. So when it comes to STELARA, we had also a very robust growth of close to 16%. In that case, there is a prior period adjustment in the quarter a year ago that represents about 600 basis points. So you should take that into consideration when you think about the STELARA growth. We are very pleased overall, as I said, with our immunology portfolio. Overall, our immunology portfolio in the quarter grew 12.4%, which is very strong considering that we also have headwinds there of REMICADE biosimilars. And we remain very excited about the immunology portfolio as a key driver for J&J. Our Innovative Medicines are going to be bringing significant improvements in IBD with TREMFYA as I recall, but also staying there, we have our target oral peptide which is going to be presenting some data soon that we already presented data in psoriasis. And also, we have the combination of [Technical Difficulty] and golimumab in IBD, which has presented also groundbreaking result, so very encouraged about our immunology portfolio and the ability to drive growth in the second-half of the decade more to be seen in our EBR later in the year.\\nOperator: Thank you. Next question is coming from Danielle Antalffy from UBS. Your line is now live.\\nDanielle Antalffy: Hey, good morning, everyone. Thanks so much for taking the question. Ahmet, I wanted to actually bring you into the conversation here and ask about some of the innovation in MedTech and specifically, you guys have an Ottava Day coming up. And just curious what you can say about, a, what we get to see, obviously, appreciating you're not going to totally open the kimono and front run the day? But b, and probably most importantly, sort of, where you see Ottava ultimately fitting into the robotics landscape and helping contribute to a continued move higher robotics penetration? Thanks so much.\\nAhmet Tezel: So first of all, thank you for the question. Similar to John, this is my first call as well. So really excited to be here, equally excited to be leading a team of talented scientists, engineers and physicians as we do smarter less invasive and more personalized solutions for our patients. So with respect to Ottava, we have made great progress on the platform. The team is really focused on combining a really differentiated architecture based on its software and hardware together with our best-in-class instruments, and we believe that combination of a differentiated architecture with instruments is going to enable us to have high value from day one. Now we will have more updates on Ottava next month, as you mentioned. And at that time, we will provide a lot more detail. But the one point I'll make is that even today, robotic-assisted surgery penetration is in single-digits. So there's still a lot of growth left in that segment. And we're really excited because Ottava brings a lot of differentiation. So we're very excited that we can make a big kind of path. We can open our path and growth there in that segment as well.\\nJoaquin Duato: Danielle, if I may interject here on Ottava. I've been in touch with multiple surgeons around the world. And one common comment that I find is that they all want. They are rooting for Johnson & Johnson to come into the robotic surgical space. They want to have the service and the support that they have accustomed doing decades with our Ethicon business and they also want to be able to utilize the advanced instruments with whom they have grown. So what I see in the surgical space is that the surgeons want to have alternatives and they are all looking forward to having Johnson & Johnson play an important role in robotic surgery.\\nJessica Moore: Thank you, Danielle. We have time for one last question.\\nOperator: Thank you. Our final question today is coming from Louise Chen from Cantor Fitzgerald. Your line is now live.\\nLouise Chen: Hi, thanks for taking my question. I wanted to ask you on the FLORA 2 results, if they impacted at all your thinking on your market opportunity for MARIPOSA and why or why not? Thank you.\\nAhmet Tezel: No, I don't think it influences because it's really important to pay attention not only to progression-free survival, but also overall survival as well as the PFS-2 the survival in the second line of therapy. Unfortunately, with today's therapies, almost all lung cancer patients will eventually relapse. They will need a second line therapy. And we think chemo was best reserved for that circumstance where the patient now has failed the frontline targeted therapies. So I would really say, pay attention to overall survival, pay attention to that progression free survival to endpoint, because these are going to be, I think, really things that matter in terms of what the long-term outcome is for patients with EGF receptor mutant lung cancer. The -- we believe based on the data we'll present in the Presidential session at ESMO that the combination of RYBREVANT are bispecific antibody, the first bispecific ever approved for a solid tumor indication in elderly human as well as the third-generation small molecule oral EGF receptor Lazertinib, which is brain penetrant over mine. We believe that, that will become the new frontline standard-of-care for EGF receptor mutant lung cancer and offer patients durable remissions that are achieved in a chemo-free regimen.\\nOperator: Thank you.\\nJessica Moore: Thank you, and thanks to everyone for your questions and your continued interest in our company. We apologize to those that we couldn't get to because of time, but don't hesitate to reach out to the Investor Relations team with any remaining questions you may have. I will now turn the call back to Joaquin for some brief closing remarks.\\nJoaquin Duato: Thank you, Jess, and thank you to all of you for joining us today. I'm proud to present today the company's performance. This is the first quarter that we report as a new J&J, focused in health care innovation, in MedTech and in Pharmaceuticals. And I believe this new J&J has a better foundation to continue to drive growth for the next decade. We are achieving strong results in 2023 with our 7.5% adjusted operational growth in the quarter. It's the second quarter in a row that we have a beat and a risk of our guidance. And we continue to believe that we're going to have a very strong finish into 2023 and that reads well for a strong 2024, too. We have a dedicated team both in Innovative Medicines and in MedTech. And we think we are very well positioned, as I said, to carry the momentum that you are seeing in 2023 into 2024. Finally, we are looking forward to engaging all of you at Enterprise Business Review on December 5th. Thank you very much and enjoy the rest of your day.\\nOperator: Thank you. This concludes today's Johnson & Johnson's third quarter 2023 earnings conference call. You may now disconnect.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ori_df = ori_df.head(1000)\n",
        "ori_df.index = sum_df.index\n",
        "sum_df['EarningCallTranscript'] = ori_df['EarningCallTranscript']\n",
        "sum_df.info()\n",
        "\n",
        "\n",
        "sum_df.to_csv(\"final_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw8n5z9ykyKn",
        "outputId": "85bc06d0-3789-4cd1-8c9d-4491d8c3db10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 5 columns):\n",
            " #   Column                 Non-Null Count  Dtype \n",
            "---  ------                 --------------  ----- \n",
            " 0   Exchange               1000 non-null   object\n",
            " 1   Symbol                 1000 non-null   object\n",
            " 2   Year                   1000 non-null   int64 \n",
            " 3   EarningCallTranscript  1000 non-null   object\n",
            " 4   Summary                1000 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 39.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparams Tuning"
      ],
      "metadata": {
        "id": "2T66rO6pk07Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers.integrations import TensorBoardCallback\n",
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "XfxzgaLBk0Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_df = pd.read_csv('/content/final_dataset.csv')\n",
        "\n",
        "dataset = Dataset.from_pandas(sum_df)\n",
        "dataset = dataset.rename_column(\"Summary\", \"target\")\n",
        "dataset = dataset.rename_column(\"EarningCallTranscript\", \"source\")"
      ],
      "metadata": {
        "id": "rn-BNcDgl--0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "e6855b9307374106aa1cdee3dbcba5a8",
            "9230d7451a564b538f2b25c23d4b3a87",
            "52f82f4520e54cbd86ad4eac7ea2a3ed",
            "5b8799b91dfe45e3a638dffe6bc49b38",
            "d639208e7ae24eb2a34da443696f1faa",
            "b750c54ab46d4815bee32b72b694e8d1",
            "20e4b0a1c6104b46bee48165f75aba4d",
            "9a68e279e2cb41dbb47cbeff1f37bcbc",
            "c81f4bceec8b49d0812b0fa12395df7d",
            "a088d7ad75d940a38830286f843ff75c",
            "f5b8f26ad9314fbb840d2474e29e3d65",
            "6afcf446887040ad90a20db2349ea13c",
            "ee2adb6dfc0343dd82d815e5d2a4a639",
            "f09f2c3d23664e7098431f8489426a74",
            "94601652a52648418aeca63d993b2a96",
            "c95324ea395545ef894c93dd3459f9f1",
            "1bf1adffdea04cb386ea757c334c92e2",
            "4dd674902d094a62af47ec950f027975",
            "2218308a8a4342abac404607cf7386de",
            "d36b4709007e4b2f8a8ebdf3a7b5add7",
            "a04be2457b3f444a91bc2ded330801bd",
            "f268d27cf6c54d869857760d34a2e3d6",
            "c44478b52ec747d2b61edce5cdb0ecc5",
            "6976dd260c424c72bb7078af615919e6",
            "efb4c8ca2dc2464f9d0068943c685e79",
            "0ffbd2426a4a4c92891bda91c4c15438",
            "512c6cfebe1e47cbb36f0f0c90f4442a",
            "ba7038a08a694f648d98bd5fe35e37b8",
            "9f516be3f8a2422dadbc483cd7d29ef0",
            "e4c132c3d45c4947a8031cc1dba3f5e2",
            "f26305a7d9e94d44894085a4b0308999",
            "b00852f6b2be4e8d8750d6b6a277808b",
            "fc2eb2281740409c9dfca838b52d47e3",
            "221c9a99974945a1a7b4ee6cbf130d30",
            "f4e3d31125ee41a5bf5692ab0dfacdcc",
            "b818829cdffd46b4888eee3cd7e39486",
            "965047dd2558465baf1680a867f3c687",
            "27e8655572654d8496ea28a4f3d68aa3",
            "14c95410823b4e809456a856de5d25a4",
            "a0d035c351bf4479bc5828fae8116fdc",
            "343ba9cf5814441e8712fdf12b80233c",
            "e56ab636bec64851a554e02c33d3be89",
            "8a2a7879a18945fa98466b7105219fb7",
            "fa4c7c31e6484bc3a9c4b221f015aef0",
            "88950abbd9074b98b9d7ae034855100d",
            "12e98b7a1e784d919263e0deeed69ab2",
            "0138c0dbb4234d2ca3f3c66b7583836b",
            "59a0f97a7d2f4fe699494d7b21203802",
            "758ce034838b4878a9f817958c913373",
            "dcf5b9d3b8a74ccb8aef76c7347dff2d",
            "dd8ab05b58f64e3da98660f34a4bd701",
            "e5955b1587634b1b820a828add51ff9e",
            "21753c10fc114a5082507bd2e6f87e62",
            "c55552f3446f4e279a5d0f282ae30f82",
            "6002c79e13994c93b7f5231784ce8612"
          ]
        },
        "id": "uqxUQjhZmD9d",
        "outputId": "e2077e8d-a265-4903-b317-f2cff5bf3c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6855b9307374106aa1cdee3dbcba5a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6afcf446887040ad90a20db2349ea13c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c44478b52ec747d2b61edce5cdb0ecc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "221c9a99974945a1a7b4ee6cbf130d30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88950abbd9074b98b9d7ae034855100d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=1024):\n",
        "    words = text.split()\n",
        "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]"
      ],
      "metadata": {
        "id": "GHns94XlmFi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    labels = []\n",
        "\n",
        "    for source_text, target_text in zip(examples['source'], examples['target']):\n",
        "        source_text = ' '.join(source_text) if isinstance(source_text, list) else source_text\n",
        "        target_text = ' '.join(target_text) if isinstance(target_text, list) else target_text\n",
        "\n",
        "        source_chunks = chunk_text(source_text, chunk_size=1024)\n",
        "        target_chunks = chunk_text(target_text, chunk_size=1024)\n",
        "\n",
        "        for source_chunk, target_chunk in zip(source_chunks, target_chunks):\n",
        "            model_inputs = tokenizer(source_chunk, max_length=1024, truncation=True, padding=\"max_length\")\n",
        "            labels_chunk = tokenizer(target_chunk, max_length=1024, truncation=True, padding=\"max_length\")\n",
        "\n",
        "            input_ids.append(model_inputs['input_ids'])\n",
        "            attention_mask.append(model_inputs['attention_mask'])\n",
        "            labels.append(labels_chunk['input_ids'])\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=8,\n",
        "    remove_columns=dataset.column_names,\n",
        "    num_proc=4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "58937aec44f84ff2bef21dd1790d36ea",
            "f00b0c7d8c954284ae9d1e8a541bf163",
            "ecfbaa33bb834460b34e9b6874c3e996",
            "a325dd071cd9448380ea2467cf591f6b",
            "3070f1b3a43e4454beddf94ee7f2aa76",
            "31b606aea467452cbe4f91305dc036b9",
            "46a490fe18ee4803a4ba0d3afb4f69a2",
            "62d11a056412445d92e67162c2839075",
            "96d8428a37874f52befded9b6838d3df",
            "c0f22020325f4999b62c65ac545302d1",
            "8a46ddf3a92f4a88a87bbe23de6e7736"
          ]
        },
        "id": "a1v30q3nmHoX",
        "outputId": "d47768a7-a381-406a-c82d-16573ecbbb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58937aec44f84ff2bef21dd1790d36ea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.1)\n",
        "tokenized_datasets = DatasetDict({\n",
        "    'train': train_test_split['train'],\n",
        "    'test': train_test_split['test']\n",
        "})"
      ],
      "metadata": {
        "id": "OSzE-Ra5mJJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"./logs\"\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "kX6TmGbMmOCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Define the hyperparameter search space\n",
        "    args = Seq2SeqTrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
        "        per_device_train_batch_size=trial.suggest_int(\"per_device_train_batch_size\", 2, 4),  # Reduced batch size range\n",
        "        per_device_eval_batch_size=trial.suggest_int(\"per_device_eval_batch_size\", 2, 4),   # Reduced batch size range\n",
        "        weight_decay=trial.suggest_float(\"weight_decay\", 0.01, 0.1),\n",
        "        save_total_limit=3,\n",
        "        num_train_epochs=trial.suggest_int(\"num_train_epochs\", 3, 6),  # Adjusted epochs range\n",
        "        predict_with_generate=True,\n",
        "        fp16=True,\n",
        "        logging_dir=log_dir,\n",
        "        logging_steps=10,\n",
        "        report_to=[\"tensorboard\"],\n",
        "        gradient_accumulation_steps=trial.suggest_int(\"gradient_accumulation_steps\", 1, 4)  # Added gradient accumulation\n",
        "    )\n",
        "\n",
        "    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"test\"],\n",
        "        tokenizer=tokenizer,\n",
        "        callbacks=[TensorBoardCallback()]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    return eval_results[\"eval_loss\"]"
      ],
      "metadata": {
        "id": "75agz4ComQW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters: \", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "65abdb07e8af46918521a134ae8a9d6b",
            "d758e4a2c70a49adae8bc25ae6d0d2bd",
            "c0497028630b4866aff2ca9d0606ac10",
            "5afe6fba1d52413988fdcc387a40aae8",
            "0ec14907b25d4e3a99a8c544f05bebc0",
            "1137b60631b44c3286bb2835f4479d04",
            "44e188ba62464fe9b5375cc6cd7c5da4",
            "ccaec4919257482f86c258c3986b78ee",
            "6dda53dc9f204288a71ad81ac2438395",
            "57b02139ff1144cda4f1ea8e09ac8b5b",
            "b00850bd2cc34b4295ebb824e050d7fc"
          ]
        },
        "id": "yN3Qz3OnmSAk",
        "outputId": "b7e8f668-7193-494d-b0d4-256fbd946936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 04:50:45,715] A new study created in memory with name: no-name-e64e7dca-1f21-4b36-be42-7f14ad6cbbbc\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65abdb07e8af46918521a134ae8a9d6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 14:03, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.263600</td>\n",
              "      <td>1.874167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>1.515134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.440400</td>\n",
              "      <td>1.479219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.561700</td>\n",
              "      <td>1.464103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.453600</td>\n",
              "      <td>1.458783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.394000</td>\n",
              "      <td>1.455372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 05:05:02,183] Trial 0 finished with value: 1.4553719758987427 and parameters: {'learning_rate': 2.519307357896815e-05, 'per_device_train_batch_size': 3, 'per_device_eval_batch_size': 2, 'weight_decay': 0.045285978082986574, 'num_train_epochs': 6, 'gradient_accumulation_steps': 2}. Best is trial 0 with value: 1.4553719758987427.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 14:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.366000</td>\n",
              "      <td>2.996696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.228600</td>\n",
              "      <td>1.902592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.625800</td>\n",
              "      <td>1.562594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.717500</td>\n",
              "      <td>1.512902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.599800</td>\n",
              "      <td>1.499914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.538100</td>\n",
              "      <td>1.493852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 05:19:39,176] Trial 1 finished with value: 1.4938522577285767 and parameters: {'learning_rate': 1.2891500639873349e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 4, 'weight_decay': 0.037966131823975596, 'num_train_epochs': 6, 'gradient_accumulation_steps': 3}. Best is trial 0 with value: 1.4553719758987427.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 06:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.330000</td>\n",
              "      <td>2.637571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.920300</td>\n",
              "      <td>1.617452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.773000</td>\n",
              "      <td>1.531465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 05:26:01,330] Trial 2 finished with value: 1.5314652919769287 and parameters: {'learning_rate': 4.501866566397143e-05, 'per_device_train_batch_size': 3, 'per_device_eval_batch_size': 3, 'weight_decay': 0.019431637827351432, 'num_train_epochs': 3, 'gradient_accumulation_steps': 4}. Best is trial 0 with value: 1.4553719758987427.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 10:28, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.266700</td>\n",
              "      <td>3.596243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.974800</td>\n",
              "      <td>2.569660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.379400</td>\n",
              "      <td>1.947003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.041100</td>\n",
              "      <td>1.703398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.836400</td>\n",
              "      <td>1.647868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 05:36:37,795] Trial 3 finished with value: 1.6478676795959473 and parameters: {'learning_rate': 2.0107549891170385e-05, 'per_device_train_batch_size': 3, 'per_device_eval_batch_size': 2, 'weight_decay': 0.052033284726624794, 'num_train_epochs': 5, 'gradient_accumulation_steps': 4}. Best is trial 0 with value: 1.4553719758987427.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2700/2700 20:18, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.862700</td>\n",
              "      <td>1.549044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.715300</td>\n",
              "      <td>1.489331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.370600</td>\n",
              "      <td>1.468311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.531100</td>\n",
              "      <td>1.458922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.508500</td>\n",
              "      <td>1.454424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.465700</td>\n",
              "      <td>1.454548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 05:57:02,317] Trial 4 finished with value: 1.4545478820800781 and parameters: {'learning_rate': 1.5838285311682977e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 4, 'weight_decay': 0.05717848683581232, 'num_train_epochs': 6, 'gradient_accumulation_steps': 1}. Best is trial 4 with value: 1.4545478820800781.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1800/1800 13:24, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.820500</td>\n",
              "      <td>1.521705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.657400</td>\n",
              "      <td>1.464067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.305100</td>\n",
              "      <td>1.445805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.451200</td>\n",
              "      <td>1.439991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 06:10:32,577] Trial 5 finished with value: 1.4399908781051636 and parameters: {'learning_rate': 2.8023652601511377e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.08233597332385283, 'num_train_epochs': 4, 'gradient_accumulation_steps': 1}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 10:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.820300</td>\n",
              "      <td>1.530387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.655400</td>\n",
              "      <td>1.474311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.317100</td>\n",
              "      <td>1.461044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 06:20:38,830] Trial 6 finished with value: 1.4610435962677002 and parameters: {'learning_rate': 2.821101912531759e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 4, 'weight_decay': 0.0978245389591281, 'num_train_epochs': 3, 'gradient_accumulation_steps': 1}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1125/1125 13:02, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.748900</td>\n",
              "      <td>1.600979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.545700</td>\n",
              "      <td>1.493932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.452700</td>\n",
              "      <td>1.472700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.605900</td>\n",
              "      <td>1.461522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.418900</td>\n",
              "      <td>1.458162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 06:33:47,223] Trial 7 finished with value: 1.4581618309020996 and parameters: {'learning_rate': 2.3555128856718638e-05, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4, 'weight_decay': 0.06251552006447035, 'num_train_epochs': 5, 'gradient_accumulation_steps': 1}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 14:29, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.371600</td>\n",
              "      <td>1.985011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.720600</td>\n",
              "      <td>1.510539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.448700</td>\n",
              "      <td>1.471287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.569400</td>\n",
              "      <td>1.456707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.466200</td>\n",
              "      <td>1.452622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.405200</td>\n",
              "      <td>1.448290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 06:48:23,841] Trial 8 finished with value: 1.448290467262268 and parameters: {'learning_rate': 2.358280970679745e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.018901216720972298, 'num_train_epochs': 6, 'gradient_accumulation_steps': 3}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [168/168 06:09, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.869900</td>\n",
              "      <td>4.091247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.006100</td>\n",
              "      <td>3.653920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.787100</td>\n",
              "      <td>3.565995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 06:54:41,377] Trial 9 finished with value: 3.56599497795105 and parameters: {'learning_rate': 1.011365394050913e-05, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 3, 'weight_decay': 0.045171189984175325, 'num_train_epochs': 3, 'gradient_accumulation_steps': 4}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 10:32, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.660200</td>\n",
              "      <td>1.554225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.510600</td>\n",
              "      <td>1.474148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.518100</td>\n",
              "      <td>1.451520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.543900</td>\n",
              "      <td>1.444914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 07:05:20,337] Trial 10 finished with value: 1.4449138641357422 and parameters: {'learning_rate': 3.810556320443432e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.08673420270685073, 'num_train_epochs': 4, 'gradient_accumulation_steps': 2}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 10:36, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.650500</td>\n",
              "      <td>1.541276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.502200</td>\n",
              "      <td>1.470896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.387900</td>\n",
              "      <td>1.449698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.526300</td>\n",
              "      <td>1.441582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 07:16:03,693] Trial 11 finished with value: 1.441582441329956 and parameters: {'learning_rate': 4.0347323314009976e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.09273669515557838, 'num_train_epochs': 4, 'gradient_accumulation_steps': 2}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 10:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.686200</td>\n",
              "      <td>1.564206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.538400</td>\n",
              "      <td>1.481629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.419400</td>\n",
              "      <td>1.457831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.577100</td>\n",
              "      <td>1.449560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 07:26:43,852] Trial 12 finished with value: 1.4495595693588257 and parameters: {'learning_rate': 3.3984519486682483e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.07466959047099511, 'num_train_epochs': 4, 'gradient_accumulation_steps': 2}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1200/1200 11:21, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.912800</td>\n",
              "      <td>1.530723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.467500</td>\n",
              "      <td>1.473124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.231400</td>\n",
              "      <td>1.452119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.425500</td>\n",
              "      <td>1.446675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 07:38:11,879] Trial 13 finished with value: 1.446675419807434 and parameters: {'learning_rate': 4.984595023401994e-05, 'per_device_train_batch_size': 3, 'per_device_eval_batch_size': 2, 'weight_decay': 0.09960673100589063, 'num_train_epochs': 4, 'gradient_accumulation_steps': 1}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 10:40, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.666000</td>\n",
              "      <td>1.550919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.514000</td>\n",
              "      <td>1.474852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.403500</td>\n",
              "      <td>1.453937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.558600</td>\n",
              "      <td>1.446669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 07:48:58,956] Trial 14 finished with value: 1.4466689825057983 and parameters: {'learning_rate': 3.4036757060821446e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.07558254499739749, 'num_train_epochs': 4, 'gradient_accumulation_steps': 2}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 11:06, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.986400</td>\n",
              "      <td>2.517511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.824300</td>\n",
              "      <td>1.560697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.532000</td>\n",
              "      <td>1.499345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.605100</td>\n",
              "      <td>1.476690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.500600</td>\n",
              "      <td>1.469220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 08:00:13,147] Trial 15 finished with value: 1.4692199230194092 and parameters: {'learning_rate': 2.954690891737078e-05, 'per_device_train_batch_size': 3, 'per_device_eval_batch_size': 2, 'weight_decay': 0.08359569489782559, 'num_train_epochs': 5, 'gradient_accumulation_steps': 3}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1800/1800 13:27, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.853000</td>\n",
              "      <td>1.533501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.707300</td>\n",
              "      <td>1.475430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.366600</td>\n",
              "      <td>1.458460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.534800</td>\n",
              "      <td>1.452943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 08:13:47,223] Trial 16 finished with value: 1.4529428482055664 and parameters: {'learning_rate': 1.8201525589289986e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.06723458102278006, 'num_train_epochs': 4, 'gradient_accumulation_steps': 1}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 11:42, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.785100</td>\n",
              "      <td>1.571191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.646400</td>\n",
              "      <td>1.488587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.381000</td>\n",
              "      <td>1.466661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.489800</td>\n",
              "      <td>1.454160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.388900</td>\n",
              "      <td>1.449429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 08:25:36,281] Trial 17 finished with value: 1.4494291543960571 and parameters: {'learning_rate': 4.003066408737272e-05, 'per_device_train_batch_size': 3, 'per_device_eval_batch_size': 2, 'weight_decay': 0.08851905770941296, 'num_train_epochs': 5, 'gradient_accumulation_steps': 2}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [675/675 07:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.682500</td>\n",
              "      <td>1.566687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.528500</td>\n",
              "      <td>1.493348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.456600</td>\n",
              "      <td>1.475184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 08:33:29,048] Trial 18 finished with value: 1.4751839637756348 and parameters: {'learning_rate': 3.0366035468605182e-05, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4, 'weight_decay': 0.07963122155915037, 'num_train_epochs': 3, 'gradient_accumulation_steps': 1}. Best is trial 5 with value: 1.4399908781051636.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [900/900 10:31, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.657800</td>\n",
              "      <td>1.550954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.550900</td>\n",
              "      <td>1.473688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.391200</td>\n",
              "      <td>1.452976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.529500</td>\n",
              "      <td>1.445122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-23 08:44:07,177] Trial 19 finished with value: 1.4451216459274292 and parameters: {'learning_rate': 4.06594428455066e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.09110278428144425, 'num_train_epochs': 4, 'gradient_accumulation_steps': 2}. Best is trial 5 with value: 1.4399908781051636.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'learning_rate': 2.8023652601511377e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 3, 'weight_decay': 0.08233597332385283, 'num_train_epochs': 4, 'gradient_accumulation_steps': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best hyperparameters for the final training\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    per_device_train_batch_size=best_params[\"per_device_train_batch_size\"],\n",
        "    per_device_eval_batch_size=best_params[\"per_device_eval_batch_size\"],\n",
        "    weight_decay=best_params[\"weight_decay\"],\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=best_params[\"num_train_epochs\"],\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=10,\n",
        "    report_to=[\"tensorboard\"]\n",
        ")\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[TensorBoardCallback()]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UfAVcbLq1MS",
        "outputId": "d8984f20-bd0a-4e78-c03e-c1ac46eca9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
            ":DefaultFlowCallback\n",
            "TensorBoardCallback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "_fd2SXBJmTxr",
        "outputId": "7bff606d-1ebb-4198-b220-05d0efe4707e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1800/1800 13:23, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.823400</td>\n",
              "      <td>1.520738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.661000</td>\n",
              "      <td>1.465809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.307800</td>\n",
              "      <td>1.446562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.451400</td>\n",
              "      <td>1.440279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1800, training_loss=1.7487749926249185, metrics={'train_runtime': 804.1808, 'train_samples_per_second': 4.477, 'train_steps_per_second': 2.238, 'total_flos': 7801576567603200.0, 'train_loss': 1.7487749926249185, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "Ib16uxhXO66w",
        "outputId": "73bdcd4b-534f-4ce5-e0a5-064b3fd46880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.440279245376587, 'eval_runtime': 3.884, 'eval_samples_per_second': 25.746, 'eval_steps_per_second': 8.754, 'epoch': 4.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./finetuned_model\")\n",
        "tokenizer.save_pretrained(\"./finetuned_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEbqz6pXO-Gf",
        "outputId": "bd67c08b-192f-4a28-de79-de8bd519544a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned_model/tokenizer_config.json',\n",
              " './finetuned_model/special_tokens_map.json',\n",
              " './finetuned_model/vocab.json',\n",
              " './finetuned_model/merges.txt',\n",
              " './finetuned_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}